{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST-SKLEARN-NN\n",
    "\n",
    "The following script executes a program for digit recognition on the mnist database using SKLearn Multi-layer Perceptron classifier and PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.datasets import mnist\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "### Configurations\n",
    "# Training-Size\n",
    "num_train = 15000                   # 60000 for full data set \n",
    "num_test  = 2500                    # 10000 for full data set\n",
    "\n",
    "\n",
    "# Use GridSearchCV to look up optimal parameters (see below)\n",
    "hyper_parameter_search = False       # True/False: Run hyper-parameter search via GridSearchCV. Takes a long time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple function to log information\n",
    "training_results = 'sklearn-nn-training-log.txt'\n",
    "def log_training_results(*s):\n",
    "    with open(training_results, 'a') as f:\n",
    "        for arg in s:\n",
    "            print(arg, file=f)\n",
    "            print(arg)\n",
    "\n",
    "# Simple function to log information\n",
    "hyperparameter_search_log = 'sklearn-nn-hyperparameter-tuning-log.txt'\n",
    "def log_hyperparameter_search(*s):\n",
    "    with open(hyperparameter_search_log, 'a') as f:\n",
    "        for arg in s:\n",
    "            print(arg, file=f)\n",
    "            print(arg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch MNIST-Data from Keras repository\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data:\t\t (60000, 28, 28)\n",
      "Shape of training labels:\t (60000,)\n",
      "Shape of testing data:\t\t (10000, 28, 28)\n",
      "Shape of testing labels:\t (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Display (Train) (Test) datasets\n",
    "print(\"Shape of training data:\\t\\t\", X_train.shape)\n",
    "print(\"Shape of training labels:\\t\", y_train.shape)\n",
    "print(\"Shape of testing data:\\t\\t\", X_test.shape)\n",
    "print(\"Shape of testing labels:\\t\", y_test.shape)\n",
    "\n",
    "# i.e.: We have 60000 images with a size of 28x28 pixels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x2000 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize some examples\n",
    "num_classes = 10 # 0 .. 9\n",
    "f, ax = plt.subplots(1, num_classes, figsize=(20,20))\n",
    "for i in range(0, num_classes):\n",
    "  sample = X_train[y_train == i][0]\n",
    "  ax[i].imshow(sample, cmap='gray')\n",
    "  ax[i].set_title(\"Label: {}\".format(i), fontsize=16)\n",
    "  ax[i].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data such that we have access to every pixel of the image\n",
    "# The reason to access every pixel is that only then we can apply deep learning ideas and can assign color code to every pixel.\n",
    "train_data = X_train.reshape((X_train.shape[0], 28*28)).astype('float32')\n",
    "train_label = y_train.astype(\"float32\")\n",
    "\n",
    "test_data = X_test.reshape((X_test.shape[0], 28*28)).astype('float32')\n",
    "test_label = y_test.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We know the RGB color code where different values produce various colors. It is also difficult to remember every color combination. \n",
    "# We already know that each pixel has its unique color code and also we know that it has a maximum value of 255. \n",
    "# To perform Machine Learning, it is important to convert all the values from 0 to 255 for every pixel to a range of values from 0 to 1.\n",
    "train_data = train_data / 255\n",
    "test_data = test_data / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force the amount of columns to fit the necessary sizes required by the neural network\n",
    "#train_label = keras.utils.to_categorical(train_label, num_classes)\n",
    "#test_label = keras.utils.to_categorical(test_label, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As an optional step, we decrease the training and testing data size, such that the algorithms perform their execution in acceptable time\n",
    "train_data = train_data[1:num_train,]\n",
    "train_label = train_label[1:num_train]\n",
    "\n",
    "test_data = test_data[1:num_test,]\n",
    "test_label = test_label[1:num_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped training data:\t\t (14999, 784)\n",
      "Reshaped training labels:\t (14999,)\n",
      "Reshaped testing data:\t\t (2499, 784)\n",
      "Reshaped testing labels:\t (2499,)\n"
     ]
    }
   ],
   "source": [
    "# Display (Train) (Test) datasets\n",
    "\n",
    "print(\"Reshaped training data:\\t\\t\", train_data.shape)\n",
    "print(\"Reshaped training labels:\\t\", train_label.shape)\n",
    "print(\"Reshaped testing data:\\t\\t\", test_data.shape)\n",
    "print(\"Reshaped testing labels:\\t\", test_label.shape)\n",
    "\n",
    "# As we can see: We now have X images with 784 pixels in total\n",
    "# We now operate on this data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-layer Perceptron classifier\n",
    "\n",
    "This model optimizes the log-loss function using LBFGS or stochastic gradient descent.\n",
    "\n",
    "For more information, see: https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The default layout of mlp() \n",
    "# @see https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(100,),      # The ith element represents the number of neurons in the ith hidden layer.\n",
    "    activation='relu',              # Activation function for the hidden layer.\n",
    "    solver='adam',                  # The solver for weight optimization.\n",
    "    alpha=0.0001,                   # Strength of the L2 regularization term. The L2 regularization term is divided by the sample size when added to the loss.\n",
    "    batch_size='auto',              # Size of minibatches for stochastic optimizers. If the solver is ‘lbfgs’, the classifier will not use minibatch. When set to “auto”, batch_size=min(200, n_samples).\n",
    "    learning_rate='constant',       # Learning rate schedule for weight updates.\n",
    "    learning_rate_init=0.001,       # The initial learning rate used. It controls the step-size in updating the weights. Only used when solver=’sgd’ or ‘adam’.\n",
    "    power_t=0.5,                    # The exponent for inverse scaling learning rate. It is used in updating effective learning rate when the learning_rate is set to ‘invscaling’. Only used when solver=’sgd’.\n",
    "    max_iter=200,                   # Maximum number of iterations. The solver iterates until convergence (determined by ‘tol’) or this number of iterations.\n",
    "    shuffle=True,                   # Whether to shuffle samples in each iteration. Only used when solver=’sgd’ or ‘adam’.\n",
    "    random_state=None,              # Determines random number generation for weights and bias initialization, train-test split if early stopping is used, and batch sampling when solver=’sgd’ or ‘adam’.\n",
    "    tol=0.0001,                     # Tolerance for the optimization. When the loss or score is not improving by at least tol for n_iter_no_change consecutive iterations, unless learning_rate is set to ‘adaptive’, convergence is considered to be reached and training stops.\n",
    "    verbose=False,                  # Whether to print progress messages to stdout.\n",
    "    warm_start=False,               # When set to True, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution.\n",
    "    momentum=0.9,                   # Momentum for gradient descent update. Should be between 0 and 1. Only used when solver=’sgd’.\n",
    "    nesterovs_momentum=True,        # Whether to use Nesterov’s momentum. Only used when solver=’sgd’ and momentum > 0.\n",
    "    early_stopping=False,           # Whether to use early stopping to terminate training when validation score is not improving. \n",
    "    validation_fraction=0.1,        # The proportion of training data to set aside as validation set for early stopping. Only used if early_stopping is True.\n",
    "    beta_1=0.9,                     # Exponential decay rate for estimates of first moment vector in adam, should be in [0, 1). Only used when solver=’adam’.\n",
    "    beta_2=0.999,                   # Exponential decay rate for estimates of second moment vector in adam, should be in [0, 1). Only used when solver=’adam’.\n",
    "    epsilon=1e-08,                  # Value for numerical stability in adam. Only used when solver=’adam’.\n",
    "    n_iter_no_change=10,            # Maximum number of epochs to not meet tol improvement. Only effective when solver=’sgd’ or ‘adam’.\n",
    "    max_fun=15000                   # Only used when solver=’lbfgs’. Maximum number of loss function calls. \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-09-09 12:08:11.707880] Trained new model: {'MLP': {'activation': 'relu', 'alpha': 0.0001, 'epsilon': 1e-08, 'hidden_layer_sizes': (100,)}} in 14.891449928283691 seconds\n"
     ]
    }
   ],
   "source": [
    "# Fit the model to data matrix X and target(s) y.\n",
    "#   X ... ndarray or sparse matrix of shape (n_samples, n_features), the input data\n",
    "#   y ... ndarray of shape (n_samples,) or (n_samples, n_outputs), the target values (class labels in classification, real numbers in regression)\n",
    "\n",
    "start_time = time.time()\n",
    "mlp.fit(train_data, train_label)\n",
    "end_time = time.time() - start_time\n",
    "\n",
    "params = {\"MLP\":{'activation':mlp.get_params()[\"activation\"], 'alpha':mlp.get_params()[\"alpha\"], 'epsilon':mlp.get_params()[\"epsilon\"], 'hidden_layer_sizes':mlp.get_params()[\"hidden_layer_sizes\"]}}\n",
    "log_training_results(\"[%s] Trained new model: %s in %s seconds\" % (datetime.now(), params, end_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tRunning Predictions on Test-Data --  execution time: 0.011055707931518555s\n"
     ]
    }
   ],
   "source": [
    "# Predict using the multi-layer perceptron classifier.\n",
    "#   X ... {array-like, sparse matrix} of shape (n_samples, n_features)\n",
    "start_time = time.time()\n",
    "predictions = mlp.predict(test_data)\n",
    "end_time = time.time() - start_time\n",
    "\n",
    "log_training_results(\"\\tRunning Predictions on Test-Data --  execution time: %ss\" % (end_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore data on {'MLP': {'activation': 'relu', 'alpha': 0.0001, 'epsilon': 1e-08, 'hidden_layer_sizes': (100,)}} -- mean accuracy on train-data: 1.0; execution time: 0.05613255500793457s\n",
      "\tScore data on {'MLP': {'activation': 'relu', 'alpha': 0.0001, 'epsilon': 1e-08, 'hidden_layer_sizes': (100,)}} -- mean accuracy on test-data: 0.9491796718687475; execution time: 0.008677959442138672s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "score = mlp.score(train_data, train_label)\n",
    "end_time = time.time() - start_time\n",
    "log_training_results(\"\\tScore data on %s -- mean accuracy on train-data: %s; execution time: %ss\" % (params, score, end_time))  \n",
    "\n",
    "start_time = time.time()\n",
    "score = mlp.score(test_data, test_label)\n",
    "end_time = time.time() - start_time\n",
    "log_training_results(\"\\tScore data on %s -- mean accuracy on test-data: %s; execution time: %ss\" % (params, score, end_time))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Hyperparameter search -- Takes up a long time.\n",
    "if hyper_parameter_search:\n",
    "    mlp = MLPClassifier(max_iter=100)\n",
    "    parameters = {\n",
    "        'hidden_layer_sizes': [(28,28),(784,)],\n",
    "        'activation': ['tanh', 'relu'],\n",
    "        'solver': ['sgd', 'adam'],\n",
    "        'alpha': [0.0001, 0.05],\n",
    "        'learning_rate': ['constant','adaptive'],\n",
    "    }\n",
    "\n",
    "    log_hyperparameter_search(\"--- [%s] Running Parameter-Tests [SKLEARN-NN] ---\" % datetime.now())\n",
    "\n",
    "    grid = GridSearchCV(estimator=mlp, param_grid=parameters, verbose=3, n_jobs=-1)\n",
    "    grid.fit(train_data, train_label)\n",
    "\n",
    "    log_hyperparameter_search(\"Best parameters set found on following development set:\")\n",
    "    log_hyperparameter_search(\"\\tSupport Vector: %s\" % grid.best_estimator_)\n",
    "    log_hyperparameter_search(\"\\tSupport Vector Parametrization: %s\" % grid.best_params_)\n",
    "    log_hyperparameter_search(\"\\tAsserted Score: %s\" % grid.best_score_)\n",
    "    log_hyperparameter_search(\"Total Score \\t\\t Configurations\")\n",
    "    means = grid.cv_results_[\"mean_test_score\"]\n",
    "    stds = grid.cv_results_[\"std_test_score\"]\n",
    "    params = grid.cv_results_[\"params\"]\n",
    "    for mean, std, params in zip(means, stds, params):\n",
    "        log_hyperparameter_search(\"%0.3f (+/-%0.03f)\\t%r\" % (mean, std, params))\n",
    "    print(\"Wrote classifier comparisons to file \", hyperparameter_search_log)\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "\n",
    "    y_true, y_pred = test_label, grid.predict(test_data)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-layer Perceptron classifier - Principal Component Analysis\n",
    "\n",
    "This model optimizes the log-loss function using LBFGS or stochastic gradient descent, on data that is transformed using PCA.\n",
    "\n",
    "For more information, see: \n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PCA()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "PCA()"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the PCA algorithm with the datasets\n",
    "pca = PCA(\n",
    "    n_components=None, \n",
    "    copy=True, \n",
    "    whiten=False, \n",
    "    svd_solver='auto', \n",
    "    tol=0.0, \n",
    "    iterated_power='auto', \n",
    "    n_oversamples=10, \n",
    "    power_iteration_normalizer='auto', \n",
    "    random_state=None\n",
    ")\n",
    "pca.fit(train_data, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping the data based on the PCA\n",
    "pca_train_data = pca.transform(train_data)\n",
    "pca_test_data = pca.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-09-09 12:08:25.565040] Trained new model: {'MLP-PCA': {'activation': 'relu', 'alpha': 0.0001, 'epsilon': 1e-08, 'hidden_layer_sizes': (100,)}} in 11.628486633300781 seconds\n"
     ]
    }
   ],
   "source": [
    "# Fit the model to data matrix X and target(s) y.\n",
    "start_time = time.time()\n",
    "mlp.fit(pca_train_data, train_label)\n",
    "end_time = time.time() - start_time\n",
    "\n",
    "params = {\"MLP-PCA\":{'activation':mlp.get_params()[\"activation\"], 'alpha':mlp.get_params()[\"alpha\"], 'epsilon':mlp.get_params()[\"epsilon\"], 'hidden_layer_sizes':mlp.get_params()[\"hidden_layer_sizes\"]}}\n",
    "log_training_results(\"[%s] Trained new model: %s in %s seconds\" % (datetime.now(), params, end_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tRunning Predictions on Test-Data --  execution time: 0.011519432067871094s\n"
     ]
    }
   ],
   "source": [
    "# Predict using the multi-layer perceptron classifier.\n",
    "\n",
    "start_time = time.time()\n",
    "predictions = mlp.predict(pca_test_data)\n",
    "end_time = time.time() - start_time\n",
    "\n",
    "log_training_results(\"\\tRunning Predictions on Test-Data --  execution time: %ss\" % (end_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore data on {'MLP-PCA': {'activation': 'relu', 'alpha': 0.0001, 'epsilon': 1e-08, 'hidden_layer_sizes': (100,)}} -- mean accuracy on train-data: 0.12767517834522302; execution time: 0.06981945037841797s\n",
      "\tScore data on {'MLP-PCA': {'activation': 'relu', 'alpha': 0.0001, 'epsilon': 1e-08, 'hidden_layer_sizes': (100,)}} -- mean accuracy on test-data: 0.13765506202480993; execution time: 0.01327824592590332s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "score = mlp.score(train_data, train_label)\n",
    "end_time = time.time() - start_time\n",
    "log_training_results(\"\\tScore data on %s -- mean accuracy on train-data: %s; execution time: %ss\" % (params, score, end_time))  \n",
    "\n",
    "start_time = time.time()\n",
    "score = mlp.score(test_data, test_label)\n",
    "end_time = time.time() - start_time\n",
    "log_training_results(\"\\tScore data on %s -- mean accuracy on test-data: %s; execution time: %ss\" % (params, score, end_time))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Hyperparameter search -- Takes up a long time.\n",
    "if hyper_parameter_search:\n",
    "    mlp_gs = MLPClassifier(max_iter=100)\n",
    "    parameters = {\n",
    "        'hidden_layer_sizes': [(28,28),(784,)],\n",
    "        'activation': ['tanh', 'relu'],\n",
    "        'solver': ['sgd', 'adam'],\n",
    "        'alpha': [0.0001, 0.05],\n",
    "        'learning_rate': ['constant','adaptive'],\n",
    "    }\n",
    "\n",
    "    log_hyperparameter_search(\"--- [%s] Running Parameter-Tests [SKLEARN-NN] ---\" % datetime.now())\n",
    "\n",
    "\n",
    "    grid = GridSearchCV(estimator=mlp_gs, param_grid=parameters, verbose=3, n_jobs=-1)\n",
    "    grid.fit(pca_train_data, train_label)\n",
    "\n",
    "    log_hyperparameter_search(\"Best parameters set found on following development set:\")\n",
    "    log_hyperparameter_search(\"\\tSupport Vector: %s\" % grid.best_estimator_)\n",
    "    log_hyperparameter_search(\"\\tSupport Vector Parametrization: %s\" % grid.best_params_)\n",
    "    log_hyperparameter_search(\"\\tAsserted Score: %s\" % grid.best_score_)\n",
    "    log_hyperparameter_search(\"Total Score \\t\\t Configurations\")\n",
    "    means = grid.cv_results_[\"mean_test_score\"]\n",
    "    stds = grid.cv_results_[\"std_test_score\"]\n",
    "    params = grid.cv_results_[\"params\"]\n",
    "    for mean, std, params in zip(means, stds, params):\n",
    "        log_hyperparameter_search(\"%0.3f (+/-%0.03f)\\t%r\" % (mean, std, params))\n",
    "    print(\"Wrote classifier comparisons to file \", hyperparameter_search_log)\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "\n",
    "    y_true, y_pred = test_label, grid.predict(test_data)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e2b2785e650337f79381cd4c5df08c4d5dc4623a6a0d2da7e01465b331d0fcc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
