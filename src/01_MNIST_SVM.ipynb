{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST-SVM\n",
    "\n",
    "The following script executes a program for digit recognition on the mnist database using Support Vector Machines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Packages\n",
    "from datetime import datetime\n",
    "import time\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import config\n",
    "\n",
    "### Configurations\n",
    "# Training-Size\n",
    "num_train = config.num_train                   # 60000 for full data set \n",
    "num_test  = config.num_test                    # 10000 for full data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated data will be located in  c:\\Users\\auerth\\Desktop\\Study\\MNIST_Digits_Benchmark\\src/log/svm-training-log.txt c:\\Users\\auerth\\Desktop\\Study\\MNIST_Digits_Benchmark\\src/log/svm-hyperparameter-tuning-log.txt\n",
      "[2022-09-12 15:39:32.577677] on (Windows-10-10.0.19044-SP0, Intel64 Family 6 Model 140 Stepping 1, GenuineIntel) using (Train: 15000, Test: 2500)\n"
     ]
    }
   ],
   "source": [
    "# Simple function to log information\n",
    "path = os.getcwd()+\"/log\"\n",
    "logDir = os.path.exists(path)\n",
    "if not logDir:\n",
    "    os.makedirs(path)\n",
    "\n",
    "training_results = path+\"/svm-training-log.txt\"\n",
    "def log_training_results(*s):\n",
    "    with open(training_results, 'a') as f:\n",
    "        for arg in s:\n",
    "            print(arg, file=f)\n",
    "            print(arg)\n",
    "\n",
    "hyperparameter_search_log = path+\"/svm-hyperparameter-tuning-log.txt\"\n",
    "def log_hyperparameter_search(*s):\n",
    "    with open(hyperparameter_search_log, 'a') as f:\n",
    "        for arg in s:\n",
    "            print(arg, file=f)\n",
    "            print(arg)\n",
    "\n",
    "print(\"Generated data will be located in \", training_results, hyperparameter_search_log)\n",
    "log_training_results(\"[%s] on (%s, %s) using (Train: %s, Test: %s)\" % (datetime.now(), config.os, config.cpu, config.num_train, config.num_test))\n",
    "if config.hyper_parameter_search:\n",
    "    log_hyperparameter_search(\"[%s] on (%s, %s) using (Train: %s, Test: %s)\" % (datetime.now(), config.os, config.cpu, config.num_train, config.num_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch MNIST-Data from Keras repository\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data:\t\t (60000, 28, 28)\n",
      "Shape of training labels:\t (60000,)\n",
      "Shape of testing data:\t\t (10000, 28, 28)\n",
      "Shape of testing labels:\t (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Display (Train) (Test) datasets\n",
    "print(\"Shape of training data:\\t\\t\", X_train.shape)\n",
    "print(\"Shape of training labels:\\t\", y_train.shape)\n",
    "print(\"Shape of testing data:\\t\\t\", X_test.shape)\n",
    "print(\"Shape of testing labels:\\t\", y_test.shape)\n",
    "\n",
    "# i.e.: We have 60000 images with a size of 28x28 pixels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABiEAAACvCAYAAACb632EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA4TklEQVR4nO3dd3RU1drH8WeABAgh9I5SrgFEhNAEEUwk1EjvVUAUgSuIAoJeQJQioqIUAaVKE5AOwkUUsNCkiIUuEHpvAaRnv3+4yHvP2RsymczJJJnvZy3Xus8ve/bseLdnys7M41JKKQEAAAAAAAAAAPCyNL5eAAAAAAAAAAAASJ04hAAAAAAAAAAAAI7gEAIAAAAAAAAAADiCQwgAAAAAAAAAAOAIDiEAAAAAAAAAAIAjOIQAAAAAAAAAAACO4BACAAAAAAAAAAA4gkMIAAAAAAAAAADgCA4hAAAAAAAAAACAI5LFIUThwoXF5XLJ9OnTHb0fl8slLpfL0fu4Lzo6WlwulxQuXNjrc1+9elXefvttKV68uGTMmFFy5swpzz//vKxdu9br95Wase/ct3LlShk8eLDUr19f8ufPH/c7HT9+3Kv34w/Yd+45e/aszJgxQ9q0aSOhoaGSIUMGCQoKkhIlSkjPnj0lOjraa/eV2rHn3BMTEyMDBw6U559/Xv71r39JlixZJDAwUPLnzy8NGzaUb775xmv35Q/Yd567du2aFC1alMfaBGLPue/+7/Cgf1q1auXV+0vN2HcJd/jwYenRo4cUK1ZMgoKCJCQkREqUKCGdOnWSQ4cOOXKfqQ37zj2DBw+O93rncrmkaNGiXrvP1Io9lzArV66U+vXrS968eSUgIEAyZ84s5cuXl6FDh8rVq1e9fn+pFfsuYVavXi1RUVGSM2dOSZ8+vRQuXFi6du2arF5LpPP1ApAwZ8+elWrVqsn+/fslX758Ur9+fTlz5oysWrVKVq1aJaNHj5YePXr4eplIZdq0aSNXrlzx9TLgR9544w2ZPXu2pEmTRkqVKiUNGjSQ69evy9atW2Xs2LEydepUWbx4sdSsWdPXS0UqcfbsWRk6dKgEBwdLqVKlpEyZMpImTRr566+/ZNmyZbJs2TLp3r27fPbZZ75eKlK5vn37ctCKJNGhQwdjXqlSpSReCfzFV199JS+++KLcvHlTnnzySalfv77cuHFDDh48KNOnT5emTZvyhjC8Jiws7IHXORGRZcuWyaVLl+S5555LwlUhtevXr5+MHDlSREQqVKggERERcvHiRdmwYYMMHDhQZsyYIT/99JPkyZPHxytFajJw4EAZOnSoiIiUK1dOihQpIn/88Yd8/vnnMm/ePFm7dq2ULVvWx6vkECLF6dKli+zfv18iIyNl2bJlEhQUJCL/nLQ2aNBAevXqJeHh4VK6dGkfrxSpSZMmTSQ0NFTKlSsn5cqVk9y5c/t6SUjlsmfPLu+++6507txZChQoEJdfu3ZNXn75ZZk7d660atVK/vrrL8mWLZsPV4rUIm/evLJp0yapUKGCpEtnfXq0bt06qVevnowfP14aNGggtWvX9tEqkdqtWbNGJk6cKK+++qqMGzfO18tBKuf0XxYC/+v777+Xdu3aSe7cuWX+/PlSrVo1y8+jo6Mlffr0PlodUqNGjRpJo0aNjD87efKkzJo1S0REOnfunISrQmr266+/ysiRIyUgIEC++eYbyx/MnTt3TmrWrCm//fabvPPOOzJx4kQfrhSpycqVK2Xo0KGSJk0amTdvnjRr1kxERJRS8t5778ngwYOladOmsmfPHp8/ziaLr2OCe3bv3i1Lly6VtGnTypQpU+IOIEREoqKipGPHjhIbGyvvv/++D1eJ1Gjq1Kny1ltvSe3atSVXrly+Xg78wJgxY2TQoEGWAwgRkeDgYJkyZYpkzpxZLl68yFfkwGuCg4OlcuXK2gGEiMhzzz0X9/Uk3377bVIvDX4iJiZGOnfuLEWKFJERI0b4ejkA4DX37t2Tl156SWJjY2XhwoXaAYTIP1+7kS9fPh+sDv7oyy+/lHv37kmJEiWkSpUqvl4OUon7X5Fes2ZN7RP7uXLlkjfffFNERDZt2pTka0PqNXr0aBERad++fdwBhMg/XzM1aNAgKVeunBw+fDju4NWXUuQhxLlz52TMmDESFRUlRYoUkYwZM0pISIhUqFBBPvjgA7l582a8c0yaNEnKly8vmTJlkqxZs0pUVJRs3rz5gePv3r0rkydPloiICMmePbukT59eihQpIt26dZNjx45589d7oMWLF4uIyDPPPCOFChXSft6mTRsREVm+fLncuXMnSdbkT/x138G32He6oKAgKV68uIhIslhPasOeM7t/OOHrvx5Jrdh3Ir169ZLjx4/L5MmTJVOmTEl+//6GPQdf8Nd9t3z5comOjpaqVavyhq8P+Ou+e5hp06aJCJ+CcIq/7rkMGTK4NS5nzpwOr8Q/+eu+27p1q4iI1KhRQ/uZy+WSyMhIERFZsGBBkqznoVQyUKhQISUiatq0aW6NnzlzphIRVaBAARUeHq5atWqlIiMjVXBwsBIR9fTTT6ubN29qtxMRJSLq9ddfVy6XS1WtWlW1bt1alSpVSomISpcunVq0aJF2u5iYGBUREaFERAUHB6vw8HDVrFkzVbx4cSUiKkeOHGrHjh2W2xw+fFiJiCpUqJA237Rp0x74s4dp2rSpEhH1xhtvGH9+5cqVuN9x165dCZrbH7HvPHf/dzp27Fii5/I37LvEu337tsqZM2eC/j36M/Zc4v3yyy8qS5YsyuVyqY0bN3pt3tSMfZcwK1asUCKiunTpov1uPNa6hz3nvvu/w8cff6y6deumunfvrkaMGKG2b9+e4Ln8HfvOPV27dlUiot5++211584dtWDBAvX666+rrl27qhEjRqg9e/YkaD5/x75LnB9//FGJiAoICFBnzpzxypypHXvOPXv37lXp0qVTAQEBas2aNZafnT17VpUpU0aJiJo3b16C5vVX7Dv3BAQEKBFRK1euNP78gw8+UCKicuXKlaB5nZAiDyF2796tNm3apOUXL15UtWrVUiKiRo4cqf38/sbKmDGj+v777y0/GzlypBIRlSVLFu2BqE2bNkpEVL169bSfffLJJ0pEVGhoqLp7925c7sTGKleunBIR9emnnz5wTEhIiBIRtWLFigTN7Y/Yd57jjRHPse8Sb8KECXG/2+nTp702b2rFnku4gQMHqg4dOqgWLVqoihUrKhFRgYGBauzYsR7P6W/Yd+67ePGiypcvn3rkkUfUlStXtN+Nx1r3sOfcd/93MP1Tp04dHlsTgH3nnipVqigRUYMGDVJly5bV9l2aNGnUG2+8oWJjYxM0r79i3yVOx44dlYioxo0be2U+f8Cec9+ECRNUunTplIioihUrqpYtW6patWqpoKAglS9fPjVp0qQEz+mv2HfuKVCggBIRNW7cOOPPX3nllbjf8dq1awma29tS5CHEw+zbty/uP3a7+//Se/XqZbxthQoVlIioYcOGxWW7d+9WLpdL5c+fX8XExBhvFxUVpURELV++PC572MZatGiRKl68uKpevXqCfrfQ0FAlIg+9aOXPn1+JiJozZ06C5vZH7DvP8caI59h3ifP777/H/SXD8OHDvTJnaseeS7j7f6V0/5/g4GD1xRdfWJ5A4uHYd+67/wJm1apVxt+Nx1r3sOfc16ZNG7VkyRIVHR2tbty4ofbv36/GjRuncuTIoUREPfnkk+rGjRsJntcfse/cc/+vQgMCAlSOHDnUrFmz1Llz59SxY8fUhx9+qAIDA3lulwDsO8/FxMSoTJkyKRH+cDMh2HMJs3r1apU7d27twLVFixbq119/9WhOf8S+c0/79u2ViKiyZctqh/kXL15U2bJli/sdT548maC5vU3vvphC3Lt3T9avXy8bN26UU6dOyY0bN0T9c6giIiL79u174G07dOhgzF944QXZtm2brF+/Xt5++20R+afLuFJK6tatK5kzZzbeLiIiQlauXCkbN26UevXqxbv2xo0bS+PGjeMdh+SHfQdfYN/94/jx41K/fn25du2aNGjQQPr37++VeaHz9z23c+dOEfmnUfC+ffvk008/lS5dusjcuXNlyZIlD1wrEscf992iRYtkzpw50qlTJ6lTp06Cb4/E8cc9JyIye/ZsSx0aGiqhoaESFRUlZcuWlT/++EMmTpwovXr18mh+PJw/7rv7v9udO3dkzpw5UqtWrbif9enTR2JjY6Vfv37y/vvvS8+ePemL4wB/3Hcm8+bNk+vXr0v+/Pl53HWYv+65AQMGyLBhw6ROnToyZMgQefzxx+Xs2bMye/ZsGTJkiCxfvlyWLFliuQ7Ce/xx3/Xr10++/vpr+fXXX6VJkyYyZMgQKVy4sPzxxx/So0cPuXbtWtzYNGl82xo6RR5CHDhwQBo3biy7du164JiYmJgH/qxIkSIPzY8fPx6XHTp0SEREpkyZIlOmTHnous6dO/fQnyfW/Y19/fr1B465v7lCQkIcXYs/8td9B99i3/3j9OnTEhkZKUeOHJHatWvL/PnzxeVyJeka/AV77v+FhIRIxYoVZfbs2ZI1a1YZP368vPvuu/LRRx8l+VpSO3/cd+fPn5du3bpJ/vz5ZdSoUY7dD8z8cc/Fp0iRItKpUyf59NNPZfny5RxCOMBf993917GFCxc2vvHWrVs36devn1y9elV++eUXee655xxdj7/x131nMnXqVBH5583GtGnTJvn9+wt/3XOzZ8+WYcOGSenSpWX58uWSLt0/b7kWKVJEBgwYIOnSpZO33npLunbtKgcOHGAPepm/7rsnnnhCFi5cKG3btpUlS5bIkiVL4n6WPXt2GTVqlPTo0UNcLpdky5bN0bXEJ0UeQjRr1kx27dol9erVkzfffFNKliwpISEhEhAQILdv35b06dMnav77J2QiIrGxsSIiEhYWJmXKlHno7SpVqpSo+41P4cKFZceOHXL06FHjz2NiYuL+gypcuLCja/FH/rrv4FvsO5GzZ89K9erVZf/+/VKjRg1ZsmRJon9vPBh7zqxTp04yfvx4Wbx4MYcQDvDHfffzzz/L2bNnpWDBgtKoUaMHjmvevLmkT59eOnbsKB07dnRsPf7GH/ecOx5//HERsb7Qhvf4674rWrSobN++XYoWLWr8eebMmSVXrlxy7tw5OXXqlKNr8Uf+uu/s9u7dK5s2bRIRkRdffDFJ79vf+Ouemz59uoj889zt/gHE/2rTpo289dZbcvjwYTl06JCEhoY6uh5/46/7TkQkKipKDh8+LAsWLJDff/9d7t69KyVLlpRWrVrJjh07RESkWLFiEhgY6PhaHibFHULs3btXfv/9d8mdO7csXrxY+w/7wIED8c5x+PBhCQsL0/Lo6GgRESlYsGBc9sgjj4iIyDPPPCPjxo3zfOFeUK5cOVm0aJFs27bN+PP7eaZMmaRYsWJJubRUz5/3HXyHfffPXw1Ur15d9uzZI5GRkbJs2TLJkCGDr5eVarHnHuz+V0OcPXvWxytJffx93x0/fvyhb/hu3rxZRP75SDe8w9/33MNcuHBBRISvnXOAP++78uXLy9dffy3nz583/vzevXty+fJlEREJDg5OwpWlfv687+zufwoiPDxcHnvsMR+vJvXy5z13/w+GH/TNJFmyZIn73xcvXkySNfkLf95392XNmlVeeuklLf/pp59ERKRmzZpJvSSNb78MygP3/0PNnz+/8WRx1qxZ8c4xc+bMh+b/+yKvbt26IiKybNkyuXnzZkKX61X3/0puw4YNxk9DzJkzR0RE6tevLwEBAUm5tFTPn/cdfMff99358+elevXqsmvXLomMjJTly5dLxowZfb2sVM3f99zDfP/99yIiHPI7wF/3XaNGjeK+o9b0z33Hjh0TpZQMHjzYZ2tNbfx1z8UnNjZW5s+fLyIiTz31lI9Xk/r4875r2rSpuFwu2bt3r/HQdf369XLnzh1xuVxSoUIFH6ww9fLnffe/7t69KzNmzBARkc6dO/t4NambP++5AgUKiIjIli1bjD+//4clInx7ibf58757mCtXrsjkyZMlbdq00q1bN18vR8Trra49kJCO5+fOnVNp06ZVadOmVevWrbP8bNmyZSp9+vRxXb/t7ucZM2bUbjtq1CglIipz5szq1KlTlp81bdpUiYiqW7euOnz4sDbvtWvX1KxZs9Tp06fjMic6niulVMOGDZWIqBo1aqi///47Ll+5cqVKmzatSpMmjfrtt98SPK8/Yt957v7vdOzYsUTP5W/Yd+65cOGCKl26tPF6h4Rhz7ln9uzZatu2bVoeGxurFi5cqLJkyaJERE2cODFB8/or9l3i8VibMOw598yaNUvt3btXy8+cOaNatWqlREQFBASo3bt3J2hef8W+c1/79u2ViKg6deqoy5cvx+XR0dHq8ccfVyKimjdvnuB5/RH7LuGWLFmiRERlyZKF1xUeYM+557PPPlMiolwul/rqq68sPzt48KAqXry4EhEVGRmZoHn9FfvOfVu2bFGxsbGW7NixY+rZZ59VIqLeeuutBM/phGR1CFG0aFFVqVKlB/6zfft2pZRSr732mhIRlSZNGhUeHq5at26typUrp0REDRgwIN6N1atXL+VyudSzzz6rWrdurZ588kklIipt2rTq66+/1m4XExOjIiMjlYiowMBAVbFiRdWiRQvVvHlzVbFiRRUYGKhERO3ZsyfuNg/bWNOmTXvgz+Jz5swZFRoaqkRE5cuXT7Vo0UJFREQol8ulRESNHj06wXP6K/ad+9577z3Lv5P7v1PZsmXjsm7duiV4Xn/EvnNP48aN457AtWjRQnXo0MH4z+LFixM0rz9iz7mnQ4cOSkRUwYIFVVRUlGrTpo2qXbt23L8/EVH//ve/tSd3MGPfJR6HEAnDnnPP/T9oCg0NVQ0bNlRt2rRRVatWVcHBwUpEVFBQkJo/f36C5vRn7Dv3Xb58Oe53zZkzp6pXr56qUaNG3N4rU6aMunDhQoLn9Ufsu4Rr0KCBEhHVtWtXj+fwZ+w599y5c0fVq1cv7vcoVaqUat68uYqIiFAZMmSIe61x8ODBBM3rr9h37suSJYvKnz+/qlWrlmrTpo2KiIiIu/8uXbqoe/fuJXhOJySrQ4j4/rl/IhUbG6umTJmiypcvr4KDg1WWLFlU1apV1dy5c5VSKt6NpZRSEyZMUGFhYSpjxowqJCRE1alTR23YsOGBa7x3756aM2eOioqKUnny5FEBAQEqR44cqlSpUqpTp05q8eLF6vbt23HjnXwQvXLliurfv78KDQ1V6dOnV9mzZ1d16tRR3333nUfz+Sv2nfvuvzn3sH/Cw8MTPK8/Yt+5Jzw83K1/T++8806C5vVH7Dn3/Pzzz6pnz56qQoUKKm/evCogIEAFBQWpYsWKqQ4dOqiffvopQfP5O/Zd4t3/3TiEcA97zj2LFi1S7dq1U6VKlVI5c+ZU6dKlU5kzZ1ZhYWGqd+/e6tChQwmaz9+x7xLmxo0bavjw4ap06dIqKChIBQUFqbJly6oRI0bw1+kJwL5LmNOnT6t06dIpEVG//PKLR3P4O/ac+2JjY9WXX36patSoEfc4GxwcrMLCwtTAgQPVxYsXEzynv2LfuW/QoEGqcuXKKmfOnCogIEDlzZtXNW7cWK1evTrBcznJpZRSAgAAAAAAAAAA4GUprjE1AAAAAAAAAABIGTiEAAAAAAAAAAAAjuAQAgAAAAAAAAAAOIJDCAAAAAAAAAAA4AgOIQAAAAAAAAAAgCM4hAAAAAAAAAAAAI7gEAIAAAAAAAAAADginbsDXS6Xk+tACqOUSpL7Yd/hfyXFvmPP4X9xrYMvsO/gCzzGIqlxrYMvcK1DUuNaB19g38EX4tt3fBICAAAAAAAAAAA4gkMIAAAAAAAAAADgCA4hAAAAAAAAAACAIziEAAAAAAAAAAAAjuAQAgAAAAAAAAAAOIJDCAAAAAAAAAAA4AgOIQAAAAAAAAAAgCPS+XoBAAAAAADAt4oVK6Zl//3vf7Usbdq0WlaoUCFH1gQAAFIHPgkBAAAAAAAAAAAcwSEEAAAAAAAAAABwBIcQAAAAAAAAAADAERxCAAAAAAAAAAAAR9CYGgAAAAAAPzN27FhL3bJlS21M9uzZtWzFihWOrQkAAKROfBICAAAAAAAAAAA4gkMIAAAAAAAAAADgCA4hAAAAAAAAAACAIziEAAAAAAAAAAAAjqAxtReUL1/eUr/66qvamBdeeEHLZsyYoWX25mA7duxI5OoAAAAAAP4iT548WrZo0SItq1y5sqVWSmlj/vzzTy3r3LlzIlYHAAD8EZ+EAAAAAAAAAAAAjuAQAgAAAAAAAAAAOIJDCAAAAAAAAAAA4AgOIQAAAAAAAAAAgCNcytR9yjTQ5XJ6LSlCWFiYlq1du9ZSh4SEeDz/lStXLHWOHDk8nstJbm6bRGPfed+AAQO07N1337XUadLo55MRERFa9sMPP3htXe5Iin3HnnuwzJkzW+rg4GBtzPPPP69luXLl0rJRo0ZZ6lu3biVydc7gWueZYsWKaVlAQIClfvbZZ7Ux48eP17LY2FjvLcxm6dKlWtaqVSstu337tmNrMGHfpW6RkZFaNnv2bC0LDw+31Pv27XNsTSI8xnpL2rRpLXWWLFk8mufVV1/VsqCgIC0rXry4lv373/+21B999JE2pnXr1lp28+ZNSz1ixAhtjP05Y2JwrfMe++Ou6f/zqKgoLbP/u+nfv782Ztu2bVq2bt26hC4x2eBah6TGtS51yZQpk6Vev369NiZ//vxa9swzz1jq6Ohoby5Lw76DL8S37/gkBAAAAAAAAAAAcASHEAAAAAAAAAAAwBEcQgAAAAAAAAAAAEek8/UCkrOnnnpKyxYuXKhl9u96NX0H1tWrV7XM9B3T9h4QlStX1sbs2LHDrbmAjh07alm/fv20zJ3vXE+q7xRE0itcuLCWmfbJ008/balLlSrl8X3my5fPUvfs2dPjuZB0nnjiCS0zXWeaN2+uZfZeM6bvSjVdi5y89jRo0EDLJk6cqGW9evWy1DExMU4tKcUy9fiwP6dZvHhxUi0nWatYsaKWbd261QcrwX2PPvqopQ4MDNTGVKlSRcuqVq2qZVmzZrXUTZs2Tdzi4nH8+HEtGzNmjKVu3LixNsb02uS3336z1End+wuey549u6U29X9wh2k/peT+DwAgor/uMPUsNLl06ZKWPffcc5a6fPny2hhTH68LFy64dZ9AasYnIQAAAAAAAAAAgCM4hAAAAAAAAAAAAI7gEAIAAAAAAAAAADiCQwgAAAAAAAAAAOAIv21MHRQUpGXlypWz1LNmzdLG2JupuuvAgQNaNnLkSC2bO3eupd6wYYM2ZsCAAVr2/vvve7QupG6FChXSsgwZMvhgJfCVEiVKaJm9yW7btm21MRkzZtQyl8tlqY8dO6aNMTW6fPzxx7WsRYsWlnr8+PHamL1792oZfMv0WONp88vk6oUXXtCyKVOmWGrTY7O/i4iI0LLQ0FBL7a+Nqe1N2YsUKaKNMT1e26+58I6wsDAtW7t2raXOkiVLEq0mYWJjY7XM9Lrg2rVrlnr27NnamFOnTmmZvQGnqbEmfK9YsWJaNmfOHEvt7vWjSZMmlnrp0qWeLwxwQ+/evS11YGCgNsb02sH0esXO9NrhiSeeSMDqkJyUKlVKy3r27GmpTc+fTOzXzUcffdSt240YMULLSpYsaalN19sTJ05omWmvI2WoVKmSpW7Xrp02Jjw8XMvcuf706dNHy06ePKllVatWtdSm96u3bNkS7/35Gp+EAAAAAAAAAAAAjuAQAgAAAAAAAAAAOIJDCAAAAAAAAAAA4AgOIQAAAAAAAAAAgCP8tjH1559/rmWtW7d27P7sTa9FRIKDg7Xshx9+sNSmRo+lS5f22rqQetSoUUPLevTo4dZt7U286tWrp405c+aMZwuDI0xNMz/44AMta9mypZZlzpzZo/s8cOCApa5du7Y2JiAgQMtMTeJy5sz50BrJ05o1a7TM3cbUZ8+etdT2Zs8iegNfEXMjVrsqVapomak5GJxjaui9adMmH6wk+cmXL5+lfvnll7UxpuZypmsnEu/o0aNaduHCBUvtdGNqU+PAy5cvW+rnnntOG3P79m0tmzlzptfWhZShffv2WmZvsrpy5UptTNeuXbXM1DwVcIf9eZapibDpuVjjxo0ttbtN1JVS8Y4JDQ3Vst27d2uZvbEwkqfq1atrWefOnT2a69atW5ba9LzLdH/9+/ePd27T3pw+fbqW2Z9rIHkyvX8yevRoS21678J0LVu/fr2lzpUrlzbmww8/dGtd9vlNc7Vq1cqtuXyJT0IAAAAAAAAAAABHcAgBAAAAAAAAAAAcwSEEAAAAAAAAAABwhF/0hChfvryWPf/881rmzvcR2ns2iIgsX77cUn/00UfamJMnT2rZr7/+qmWXLl2y1KbvpXP3exORulWtWtVST5s2TRvj7nca27+H7siRI54vDEnC/n2qIiIvvfSS1+Y/ePCgltWsWdNSHzt2TBvz2GOPeW0NSH4mTJigZUuWLHHrtnfu3LHUp0+f9saSREQkJCREy/78808ty58/f7xzmX6fbdu2ebQuf2Lq54F/TJ48Od4x9p47cM7Fixe1rG/fvpba1BvL9Lx9zJgx8d7fzp07tcz+eCoicv36dUv9xBNPaGNee+21eO8PqcvGjRu1LCwsTMuio6Mt9euvv66Nof8D7D2KvvrqK21M0aJF3ZrL/jozU6ZM2hjT+xbbt2+31KbemZ4yPRcxrQvJz+DBg7XM/ths8uWXX2rZuXPntMz+Hp1pjOnaunr1ai2z9wMwzbVgwQItg2+lS6e//V2hQgUtmzRpkpYFBQVZ6h9//FEbM2TIEC37+eefLXX69Om1MfPnz9eyWrVqaZldSn19yitGAAAAAAAAAADgCA4hAAAAAAAAAACAIziEAAAAAAAAAAAAjuAQAgAAAAAAAAAAOCLVNaY2NZNZs2aNlpmaWCqlLPWqVau0Ma1bt9ay8PBwSz1gwABtjKkpoamBzW+//WapY2NjtTGmptr2hk47duzQxiB16dChg6V2p+GqiMj69eu1bMaMGd5YEpJQ8+bNPb6tvXnh1q1btTH9+vXTMlMjarvHH3/c43Uh+bt7966WubMvnFa7dm0ty5Ytm0dzHT9+XMtu3brl0VypVenSpbUsT548PlhJymBv3mlieq6KpGNvSL927VptzNWrV7WsTJkyWta5c2dLbW+GKaI3oTbZtWuXlnXp0iXe2yHlatiwoZZVqlRJy+yvWUVEvv76a0t98+ZN7y0MKVKNGjW0zN5w9ZFHHnF0DSVLltSy8+fPW2p7k18R8+vaadOmaVnBggXjXcPu3bvjHQPfMzUQz5gxo5YdOXLEUv/nP//Rxpw6dSre+3vssce07O2339ayXLlyaZn9MdzUVJtrcPLTrl07LTO9T2tif57esmVLbUxMTEy885hu504TahH9NaqpKXtKwCchAAAAAAAAAACAIziEAAAAAAAAAAAAjuAQAgAAAAAAAAAAOIJDCAAAAAAAAAAA4IgU35i6WLFilrpv377aGFNDQHtDJBG9gY2p0ce1a9e07Jtvvnlo7W2mBj29e/e21G3btnV0DUhapoZdL774oqU2NTG/fPmylg0dOtRr64LvvPzyy1pmalj57bffatlff/1lqc+ePeu1ddGcFk5r1aqVlpn+ezA9Vrpj0KBBHt3On0RFRWmZp/++UxvTNbBIkSLx3u7EiRNOLAcecqe5oIjIlStX4h1juj7NmzdPy0zP45C6Zc2a1VJXq1bN47kuXbpkqe0NLBPjtdde0zJ3Ghr36dPHa2tAwr355pta5mkj6lu3bmlZv379LPXmzZu1Mfv27Yt37gsXLmiZac+504Q6Ojpay9q3bx/v7eB7CxYs0LI6depomb3Z+YgRI7Qx3bt31zL7e4KjRo3Sxjz//PNadvHiRS0bNmyYpZ4wYYI2Br43ZMgQS21qPK6U0rLx48dr2YABAyy1u88T7UyN1N3Vs2dPS33u3DmP5/IlPgkBAAAAAAAAAAAcwSEEAAAAAAAAAABwBIcQAAAAAAAAAADAERxCAAAAAAAAAAAAR6SoxtTp06fXso8++shSm5olXr16VcteeOEFLdu2bZulTklNFh999FFfLwFeUrhwYS1buHChR3ONHTtWy9atW+fRXEheTp48qWWDBw9O+oXYPP30075eAlKwtm3baln//v0t9WOPPaaNCQgI8Oj+du7cqWV37tzxaC5/Urx4cbfG7dq1y+GVJD/256UierPq/fv3a2NMz1WR/Jked8uXL2+pw8PDtTE1atTQsm+//dZr60LKcO/ePUtt3zsiImnS6H8zaGpi/uOPP3q0htdffz3eMT169NCyQoUKxXu73r17a5mpufCJEyfinQsPV6tWLS2rXLmyR3MdPXpUy0zNnTds2ODR/O5wpwm1ydKlS7Xs/PnziV0OkoDpObmp2bm9MXX16tW1MTVr1tSyTz75xFK7+/7Zu+++q2Wm91jgW4MGDdIyeyPq27dva2NWr16tZf369dOyGzduxLuGDBkyaJn92mzady6XS8uGDh2qZabrW0rEJyEAAAAAAAAAAIAjOIQAAAAAAAAAAACO4BACAAAAAAAAAAA4IkX1hChbtqyWmXpA2DVs2FDLfvjhB6+sCfC2OnXqaFnp0qXjvd3333+vZaNHj/bKmpC69ezZU8syZcrk0VxPPvmkW+M2btxoqTdt2uTR/SFpmXrWmL4n2PR95+6oWrWqlimlPJorJiZGy+z9JVauXKmNcec7P+GerVu3+noJHgsJCbHUpsfmdu3aaZnpe7nthgwZomWXL192f3FINq5fv65lL7/8sqXesWOHNmbSpElaZu/ZZe9VJyLy2WefaZmn10j4nr1fSLVq1bQxpv4Ppu/sd+d778PCwrTMfp8NGjSIdx4R894/fvy4pTb1D1qwYIGWtWrVylIfOXLErTXg/5n6bwQFBcV7O/vzcRHzd+B7s/9DtmzZLLXp8fXZZ591ay77+k3P65Ay3Lp1S8tMz+Xt8ufPr2Wmfpr27903PXZOmTJFy5YsWRLvGpC0smbNqmXdu3fXMvv/x6b+D40aNfJoDaYehbNnz9YyU68nO9Pj4siRIz1aV0rAJyEAAAAAAAAAAIAjOIQAAAAAAAAAAACO4BACAAAAAAAAAAA4gkMIAAAAAAAAAADgiBTVmHrUqFFaZm8wY2o4nZKbUKdJo58TmRqUIeWyN8MZMWKEW7f7+eefLXWHDh20MVeuXPF4XUh5TA3oSpYsqWXvvPOOpY6KinJrfvv1yN1r0cmTJ7WsU6dOlvrevXtuzYWkVapUKUu9bNkybcyjjz6aVMtJkJ9++knLvvjiCx+sxH9lz57dK/OUKVNGy+zP/0TMDdELFixoqQMDA7Uxbdu21TL79c7UsHzLli1aZmqsmC6d9en29u3btTFIPQ4ePGipO3bsqI2ZNm2alrVv3/6htYhIpkyZtGzGjBladurUqfiWiSSWOXNmLStSpEi8tzM9h5o5c6aW/fXXX5a6WLFi2pi+fftqWcOGDS21qcH1t99+q2Uff/yxlmXJksVSr127Nt4x8A7T85ucOXNqmf21YZs2bbQxp0+f9t7CDLp27WqphwwZ4tbtdu3apWUtWrSw1E6vHUnLySb1pibmH330kZYdO3bMsTXAM6bn8qbrnV3Pnj21LHfu3Fpmf59CRKRBgwaW2v4aWUQkODhYy+zNsU0N0WfNmqVl169f17LUgk9CAAAAAAAAAAAAR3AIAQAAAAAAAAAAHMEhBAAAAAAAAAAAcASHEAAAAAAAAAAAwBHJtjF1vXr1tCwsLEzL7I09TE0zUzJT41dTM5OdO3cmwWqQWIULF9ayhQsXejTXoUOHLPWZM2c8mgcpQ0BAgKUuW7asNsa0l/Lly6dl9garpqaHmzZt0rI6depYalMjbBN7U1YRkSZNmljq0aNHa2Nu377t1vxIOqZmwKbMU/ZmwCLuN0C3Mz2PqFu3rqVetWqVR3P7O1OTZtNzk4kTJ1rqt99+26P7K126tJaZ9t3du3e17O+//7bUu3fv1sZMnTpVy7Zt22apf/jhB22M6XH3+PHjWpYxY0ZLvXfvXm0MUq/Fixdr2YEDB7Rs1KhRljoyMlIbM3z4cC0rVKiQlg0bNsxSnzhxIt51wllVq1bVsk8++STe202aNEnL3nvvPS3LkyePpTY1WI2KitKyq1evWur58+drY/r06aNloaGhWma/5tvnFhH5/vvvtczJ5rP+wvQawNPXmN5Uv359LRs0aFC8tzM9ntv3lwiNqFOTtGnTalm1atW0zNPXHd98842lNu1NpAym9wjOnTunZbly5bLUhw8f1saYXr+4w/T+SUxMjJbZ34s5f/68Nmb58uUerSGl4pMQAAAAAAAAAADAERxCAAAAAAAAAAAAR3AIAQAAAAAAAAAAHJFse0LYvz9XRCQwMFDLzp49a6nnzZvn2Jq8LX369Fo2ePDgeG+3du1aLXvrrbe8sSQ4rF+/flrm6fedjxgxIrHLQTJlutbZ+zEsWrTIrbneffddLbNfQzZs2KCNyZ49e7y3K1WqlFtrsH8fo4jI+++/b6mPHj2qjVmyZImW3bp1y637hHf8+eefljoiIkIb065dOy1bvXq1lt28edMra+rcubOW9ejRwytzwz3du3fXMtN3elepUsUr9+fu9WHPnj1atnnzZq+swaRLly5aZrre2Xs4AfZrq4hIixYtLLXp+6qnTZumZa+88oqW2b+vv2bNmgldIrzM1NvGHab+Dyb254WVKlVy63YNGza01Kb+N5UrV9ayn3/+Od65P/30Uy0z9ZdA6mV6rHbnO9h79uypZV988YU3loRkau7cuVpm7yEo4vl3+Ht6OyQ/ly9f1rJGjRpp2YoVKyy16f2NgwcPatnSpUu1bPr06Zb64sWL2hjTHrb3hDCN8Td8EgIAAAAAAAAAADiCQwgAAAAAAAAAAOAIDiEAAAAAAAAAAIAjOIQAAAAAAAAAAACOSLaNqd1lb1J66tQpH63k4UxNqAcMGKBlffv2tdTHjx/Xxnz88cdadu3atUSsDk4ICwvTslq1ank0l6k5zr59+zyaC8lLQECAlpmaSduvDSarVq3SsrFjx2qZvZmTqZHqypUrtezJJ5+01Ldv39bGjBw5UstMDaztjRBnz56tjfnuu++07IMPPrDUly5d0saY7Ny5061xeDhT8+Fhw4Yl6RoGDx6sZTSm9j37f5v+IDIy0q1xCxcudHglSA3sj80zZ87UxkyePFnL0qXTX849++yzljoiIkIbs379+gStD4mTNWtWLXO5XJba9HzfxPQao3Dhwg+dW0Skd+/eWmZvRF2sWDFtzJw5c7TMnflNjamReg0fPlzL0qTR/+Y1NjY23rlMDdKRcuXPn99Sd+rUSRvTtGlTLTM1k96xY4el/u2337Qxpvlz584d7zqRcm3ZskXLTO9xeIv9eZaISHh4uJbZr3eHDh1ybE0pBZ+EAAAAAAAAAAAAjuAQAgAAAAAAAAAAOIJDCAAAAAAAAAAA4AgOIQAAAAAAAAAAgCNSfGPqZcuW+XoJGlOzMFNT2ZYtW2qZvSGZqUEPUoZvv/1Wy7Jlyxbv7TZv3qxlHTt29MaSkAykTZvWUg8ZMkQb06dPHy27fv26pe7fv782Zu7cuVpmb3QpIlKhQgVLPW7cOG1M2bJltezAgQOWulu3btqYdevWaVlISIiWValSxVK3bdtWG9OgQQMtW7NmjZbZHTt2TMuKFCkS7+2QMtSuXdvXSwASZPHixb5eApKZ0qVLa1mzZs0sdcWKFbUxpibUJrt377bUP/74YwJWh6Rib7pqasLqLnvzS9Ncpn139OhRS50hQwZtzOHDh7WsWrVqWnblypV414nUIzAw0FKbXjuYmlDb9+Zrr72mjbG/5kDKFhkZaanfe+89t243YMAALbO/bm3UqJE2xtSY2v64CCRGxowZtcyd653p/Rp/wychAAAAAAAAAACAIziEAAAAAAAAAAAAjuAQAgAAAAAAAAAAOIJDCAAAAAAAAAAA4Ihk25ja5XK5ldkb0ZgaGznt9ddft9QDBw7UxmTJkkXLZs+erWUvvPCC9xYGn8qRI4eWmZrV2I0fP17Lrl275pU1wfe6dOliqU1NqP/++28te+WVVyy1qfF55cqVtczUmKtu3bqW2tRYydQwbNq0aZba1ADaJCYmRsv++9//PrQWEWndurWWtWnTJt77s1+ToQsICNCyWrVqadnatWst9Y0bNxxb04PY9/Do0aOTfA0A4K7ixYtb6ldffVUb06RJEy3LmzevR/d37949LTt16pSlduf5J5y1dOlSLevbt6+lbtiwoTbG9NwuLCxMyzJnzhzvGkyvM+2vr8+fP6+NGTx4sJadOHEi3vtD6hEUFKRl7dq1s9Q1a9Z0a66vvvrKUpveE+GalXJFRERo2ZgxY+K9XYMGDbTsu+++0zL7Y+WgQYPcWld0dLRb4wB3rF692tdLSLH4JAQAAAAAAAAAAHAEhxAAAAAAAAAAAMARHEIAAAAAAAAAAABHJNueEEoptzL7d8KZvm9u6tSpWnbhwgUts3/nZvv27bUxZcqU0bKCBQta6qNHj2pjTN8ZZvruf6RM9u/KFxFJk8azM76NGzcmdjlIxtz53sq0adNqmf17g03fz/vYY495tCbTXO+//76Wmb532kn274x9UIb4Va1a1VL/5z//0caYvsu3SJEiltrdPiDuyJ49u5ZFRUVp2ahRoyy16XuJTUz9K27evOnm6gDPmPqXFStWzFJv3rw5qZYDLzL1bDD1LrL3gChcuLDX1rBt2zYtGzZsmJYtW7bMa/cJ77hz546W2XuAmR7fNmzYoGWm18Seunr1qqWeP3++NmbVqlVeuz8kf6b+IpMmTdKyZs2axTuXqU/buHHjLDX9H1IX0+sJe3/UH374QRuzYsUKLTP1sKtXr95D5xYxPxc7d+6cvljAQ7Vr1/b1ElIsPgkBAAAAAAAAAAAcwSEEAAAAAAAAAABwBIcQAAAAAAAAAADAERxCAAAAAAAAAAAARyTbxtTusjdw7d69uzamadOmWhYTE6NloaGhHq3B3kh43bp12hh3mtEi5QgLC7PUNWrU0MaYmmzdvn1byz777DNLfebMmcQtDsna6dOnLXWuXLm0MenTp9eyMmXKxDv3ypUrtezHH3/UsiVLlljq6OhobUxSN6GGs+xNAEuVKuXW7d58801LbW9gmRimxnXlypXTMncacK5fv17LJkyYoGWmx2fAm0z7NU0a/uYnucuTJ4+lLlmypDbGfh0VESlRooTX1rBlyxZL/eGHH2pjli5dqmU0dU0Ztm/frmX2xuZvvPGGNiYiIsKj+/vyyy+17I8//tCyX3/91VKbGsbCvxQoUEDL3GlCffDgQS0bM2aMV9aElMP0mGR/bmR6rmRqQt2oUSMtGz16tKW+dOmSNmby5MlaZnpdAHiqaNGivl5CisWrIgAAAAAAAAAA4AgOIQAAAAAAAAAAgCM4hAAAAAAAAAAAAI7gEAIAAAAAAAAAADgi2Tam3rRpk5Zt3bpVyypWrBjvXHnz5tUyewM6kwsXLmjZ3Llztey1116Ldy6kLlmzZrXUpj1mcuLECS3r06ePN5aEFOLZZ5+11KaGW6bmvGfPnrXUU6dO1caYGnOZmqED7urWrZuvl6Dt/eXLl2tjTI/DN2/edGxNQEI8/fTTlnr69Om+WYgfyp49u5Z9/vnnWhYWFmapvdlwcOPGjVr28ccfa9nq1ast9Y0bN7y2BiRP33zzzUNrwGklSpTQst69e7t12/3791vqunXremVNSNly584d75hz585p2Zo1a7SsWrVq8c7VqVMnLTO9VgC86aefftKyNGn0v/E3NWr3d3wSAgAAAAAAAAAAOIJDCAAAAAAAAAAA4AgOIQAAAAAAAAAAgCOSbU+I48ePa1mTJk207JVXXrHUAwYM8Pg+R48ebaknTJigjfnrr788nh8Arl69aqlnzpypjTFlQGJ07NjRUvfo0UMb06FDB0fXcPDgQUv9999/a2NM36/5xRdfWOo///zTuwsDvMjlcvl6CX6jUqVKWta3b19L/dRTT2ljChQo4LU1mK5jY8aMsdTDhw/Xxly/ft1rawAATw0cOFDLWrZs6dZtx44da6mPHDnilTUhZduzZ0+8Y5o1a6ZlpudPFy9e1LLPPvvMUn/33XcJWB3gHabXowcOHNAye4+xf/3rX9oYU4+U1IxPQgAAAAAAAAAAAEdwCAEAAAAAAAAAABzBIQQAAAAAAAAAAHAEhxAAAAAAAAAAAMARybYxtcmpU6e0bPDgwQ+tASfs3bvXUm/cuFEbU7Vq1aRaDgA81M6dOy119+7dtTG//PKLlg0dOtRSZ8uWTRuzZMkSLVuzZo2WLV261FKfPn3atFQgxVi1apWWNW/e3Acr8U+NGzd2K3PH7t27LfWKFSu0MXfv3tWyjz/+WMsuX77s0RoAwGlPPPGEpQ4JCXHrdl988YWWrV271itrQury5ZdfallgYKClNjVE37Ztm5YtW7ZMyz755JNErA5wzvDhw7Vs8uTJlnrYsGHamB49emiZ/XlpasInIQAAAAAAAAAAgCM4hAAAAAAAAAAAAI7gEAIAAAAAAAAAADiCQwgAAAAAAAAAAOAIl1JKuTXQ5XJ6LUhB3Nw2ica+w/9Kin3HnsP/4loHX2DfwRd4jEVS41oHX/Dna90HH3xgqXv37q2NOXLkiJZFRUVp2b59+7y3sFSOax18gX2XtEJCQrRs/vz5lrpGjRramEWLFmlZp06dtOz69euJWF3SiW/f8UkIAAAAAAAAAADgCA4hAAAAAAAAAACAIziEAAAAAAAAAAAAjuAQAgAAAAAAAAAAOILG1PAITW7gC/7cSA6+wbUOvsC+gy/wGIukxrUOvuDP17rIyEhLvXr1am1M06ZNtWzp0qWOrckfcK2DL7DvfM/erHrYsGHamG7dumlZ6dKltWz37t3eW5iDaEwNAAAAAAAAAAB8gkMIAAAAAAAAAADgCA4hAAAAAAAAAACAI+gJAY/w/XLwBX/+Dlf4Btc6+AL7Dr7AYyySGtc6+ALXOiQ1rnXwBfYdfIGeEAAAAAAAAAAAwCc4hAAAAAAAAAAAAI7gEAIAAAAAAAAAADiCQwgAAAAAAAAAAOAItxtTAwAAAAAAAAAAJASfhAAAAAAAAAAAAI7gEAIAAAAAAAAAADiCQwgAAAAAAAAAAOAIDiEAAAAAAAAAAIAjOIQAAAAAAAAAAACO4BACAAAAAAAAAAA4gkMIAAAAAAAAAADgCA4hAAAAAAAAAACAIziEAAAAAAAAAAAAjvg/n7AdF3iGAWoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 2000x2000 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize some examples\n",
    "num_classes = 10 # 0 .. 9\n",
    "f, ax = plt.subplots(1, num_classes, figsize=(20,20))\n",
    "for i in range(0, num_classes):\n",
    "  sample = X_train[y_train == i][0]\n",
    "  ax[i].imshow(sample, cmap='gray')\n",
    "  ax[i].set_title(\"Label: {}\".format(i), fontsize=16)\n",
    "  ax[i].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare loaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data such that we have access to every pixel of the image\n",
    "# The reason to access every pixel is that only then we can apply deep learning ideas and can assign color code to every pixel.\n",
    "train_data = X_train.reshape((X_train.shape[0], 28*28)).astype('float32')\n",
    "train_label = y_train.astype(\"float32\")\n",
    "\n",
    "test_data = X_test.reshape((X_test.shape[0], 28*28)).astype('float32')\n",
    "test_label = y_test.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We know the RGB color code where different values produce various colors. It is also difficult to remember every color combination. \n",
    "# We already know that each pixel has its unique color code and also we know that it has a maximum value of 255. \n",
    "# To perform Machine Learning, it is important to convert all the values from 0 to 255 for every pixel to a range of values from 0 to 1.\n",
    "train_data = train_data / 255\n",
    "test_data = test_data / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As an optional step, we decrease the training and testing data size, such that the algorithms perform their execution in acceptable time\n",
    "train_data = train_data[1:num_train,]\n",
    "train_label = train_label[1:num_train]\n",
    "\n",
    "test_data = test_data[1:num_test,]\n",
    "test_label = test_label[1:num_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped training data:\t\t (14999, 784)\n",
      "Reshaped training labels:\t (14999,)\n",
      "Reshaped testing data:\t\t (2499, 784)\n",
      "Reshaped testing labels:\t (2499,)\n"
     ]
    }
   ],
   "source": [
    "# Display (Train) (Test) datasets\n",
    "\n",
    "print(\"Reshaped training data:\\t\\t\", train_data.shape)\n",
    "print(\"Reshaped training labels:\\t\", train_label.shape)\n",
    "print(\"Reshaped testing data:\\t\\t\", test_data.shape)\n",
    "print(\"Reshaped testing labels:\\t\", test_label.shape)\n",
    "\n",
    "# As we can see: We now have X images with 784 pixels in total\n",
    "# We now operate on this data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines\n",
    "\n",
    "Support vector machines (SVMs) are a set of supervised learning methods used for classification, regression and outliers detection. We use the SVM-package supplied by SKLearn.\n",
    "\n",
    "For more information, see: https://scikit-learn.org/stable/modules/svm.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The default layout of svm.svc() \n",
    "# @see https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "svm = SVC(\n",
    "    C=1.0,                          # Regularization parameter. The strength of the regularization is inversely proportional to C. Must be strictly positive. The penalty is a squared l2 penalty.\n",
    "    kernel='linear',                # Specifies the kernel type to be used in the algorithm. \n",
    "    degree=3,                       # Degree of the polynomial kernel function (‘poly’). Ignored by all other kernels.\n",
    "    gamma='scale',                  # Kernel coefficient for ‘rbf’, ‘poly’ and ‘sigmoid’.\n",
    "    coef0=0.0,                      # Independent term in kernel function. It is only significant in ‘poly’ and ‘sigmoid’.\n",
    "    shrinking=True,                 # Whether to use the shrinking heuristic. \n",
    "    probability=False,              # Whether to enable probability estimates. \n",
    "    tol=0.001,                      # Tolerance for stopping criterion.\n",
    "    cache_size=200,                 # Specify the size of the kernel cache (in MB).\n",
    "    class_weight=None,              # Set the parameter C of class i to class_weight[i]*C for SVC. If not given, all classes are supposed to have weight one. \n",
    "    verbose=False,                  # Enable verbose output. Note that this setting takes advantage of a per-process runtime setting in libsvm that, if enabled, may not work properly in a multithreaded context.\n",
    "    max_iter=-1,                    # Hard limit on iterations within solver, or -1 for no limit.\n",
    "    decision_function_shape='ovr',  # Whether to return a one-vs-rest (‘ovr’) decision function of shape (n_samples, n_classes) as all other classifiers, or the original one-vs-one (‘ovo’) decision function of libsvm which has shape (n_samples, n_classes * (n_classes - 1) / 2).\n",
    "    break_ties=False,               # If true, decision_function_shape='ovr', and number of classes > 2, predict will break ties according to the confidence values of decision_function;\n",
    "    random_state=None               # Controls the pseudo random number generation for shuffling the data for probability estimates.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained new model: {'Kernel':'linear'} in 14.568071126937866 seconds\n",
      "\t[linear]: mean accuracy on train-data: 0.9921328088539236; execution time: 18.129934310913086s\n",
      "\t[linear]: mean accuracy on test-data: 0.8935574229691877; execution time: 2.943146228790283s\n"
     ]
    }
   ],
   "source": [
    "# Evalute SVM.SVC with parameters on data below\n",
    "svm = SVC(kernel='linear')\n",
    "start_time = time.time()\n",
    "svm.fit(train_data, train_label)\n",
    "end_time = time.time() - start_time\n",
    "log_training_results(\"Trained new model: {'Kernel':'%s'} in %s seconds\" % (svm.get_params()[\"kernel\"], end_time))\n",
    "\n",
    "start_time = time.time()\n",
    "score = svm.score(train_data, train_label)\n",
    "end_time = time.time() - start_time\n",
    "log_training_results(\"\\t[%s]: mean accuracy on train-data: %s; execution time: %ss\" % (svm.get_params()[\"kernel\"], score, end_time))  \n",
    "\n",
    "start_time = time.time()\n",
    "score = svm.score(test_data, test_label)\n",
    "end_time = time.time() - start_time\n",
    "log_training_results(\"\\t[%s]: mean accuracy on test-data: %s; execution time: %ss\" % (svm.get_params()[\"kernel\"], score, end_time))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter search -- Takes up a long time.\n",
    "if config.hyper_parameter_search:\n",
    "    svm = SVC()\n",
    "    parameters = {\n",
    "            \"kernel\":[\"linear\"], \n",
    "            \"C\":[1,10,100],      \n",
    "            \"gamma\":[0.01,0.005,0.001,0.0005,0.0001],\n",
    "            #\"shrinking\":[True,False],      \n",
    "            #\"probability\":[True,False], \n",
    "            #\"tol\":[0.01,0.001,0.0001],\n",
    "    }\n",
    "    scores = [\n",
    "        'accuracy',\n",
    "        #\"precision\",    # The precision is intuitively the ability of the classifier not to label as positive a sample that is negative\n",
    "        #\"recall\",       # The recall is intuitively the ability of the classifier to find all the positive samples.\n",
    "        ]\n",
    "    for score in scores:\n",
    "        log_hyperparameter_search(\"\\t--- [%s] Running Parameter-Tests [LINEAR-SVC] ---\" % datetime.now())\n",
    "        log_hyperparameter_search(\"\\tTuning parameters for criteria [%s]\" % score)\n",
    "        # FIXME: Doesn't take accuracy as score for some reason. Refer to line below for accuracy score\n",
    "        #grid = GridSearchCV(estimator=svm, param_grid=parameters, scoring=\"%s_macro\" % score, verbose=3)\n",
    "        grid = GridSearchCV(estimator=svm, param_grid=parameters, scoring='accuracy', verbose=3, n_jobs=-1)\n",
    "        grid.fit(train_data, train_label)\n",
    "\n",
    "        log_hyperparameter_search(\"\\tBest parameters set found on following development set:\")\n",
    "        log_hyperparameter_search(\"\\t\\tSupport Vector: %s\" % grid.best_estimator_)\n",
    "        log_hyperparameter_search(\"\\t\\tSupport Vector Parametrization: %s\" % grid.best_params_)\n",
    "        log_hyperparameter_search(\"\\t\\tAsserted Score: %s\" % grid.best_score_)\n",
    "        log_hyperparameter_search(\"Total Score \\t\\t Configurations\")\n",
    "\n",
    "        means = grid.cv_results_[\"mean_test_score\"]\n",
    "        stds = grid.cv_results_[\"std_test_score\"]\n",
    "        params = grid.cv_results_[\"params\"]\n",
    "        for mean, std, params in zip(means, stds, params):\n",
    "            log_hyperparameter_search(\"%0.3f (+/-%0.03f)\\t%r\" % (mean, std, params))\n",
    "        print(\"Wrote classifier comparisons to file \", hyperparameter_search_log)\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\")\n",
    "    \n",
    "        y_true, y_pred = test_label, grid.predict(test_data)\n",
    "        log_hyperparameter_search(classification_report(y_true, y_pred))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poly SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained new model: {'Kernel':'poly'} in 22.881723403930664 seconds\n",
      "\t[poly]: mean accuracy on train-data: 0.9893992932862191; execution time: 21.307891368865967s\n",
      "\t[poly]: mean accuracy on test-data: 0.938375350140056; execution time: 3.394317865371704s\n"
     ]
    }
   ],
   "source": [
    "# Evalute SVM.SVC with parameters on data below\n",
    "svm = SVC(kernel='poly')\n",
    "start_time = time.time()\n",
    "svm.fit(train_data, train_label)\n",
    "end_time = time.time() - start_time\n",
    "log_training_results(\"Trained new model: {'Kernel':'%s'} in %s seconds\" % (svm.get_params()[\"kernel\"], end_time))\n",
    "\n",
    "start_time = time.time()\n",
    "score = svm.score(train_data, train_label)\n",
    "end_time = time.time() - start_time\n",
    "log_training_results(\"\\t[%s]: mean accuracy on train-data: %s; execution time: %ss\" % (svm.get_params()[\"kernel\"], score, end_time))  \n",
    "\n",
    "start_time = time.time()\n",
    "score = svm.score(test_data, test_label)\n",
    "end_time = time.time() - start_time\n",
    "log_training_results(\"\\t[%s]: mean accuracy on test-data: %s; execution time: %ss\" % (svm.get_params()[\"kernel\"], score, end_time))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter search -- Takes up a long time.\n",
    "if config.hyper_parameter_search:\n",
    "    svm = SVC()\n",
    "    parameters = {\n",
    "            \"kernel\":[\"poly\"], \n",
    "            \"C\":[1,10,50,100],            \n",
    "            \"gamma\":[0.01,0.005,0.001,0.0005,0.0001],        \n",
    "            #\"coef0\":[0.0, 0.5],\n",
    "            #\"degree\":[3,5,10],                \n",
    "            #\"shrinking\":[True,False],      \n",
    "            #\"probability\":[True,False], \n",
    "            #\"tol\":[0.01,0.001,0.0001],\n",
    "    }\n",
    "    scores = [\n",
    "        \"accuracy\",\n",
    "        #\"precision\",    # The precision is intuitively the ability of the classifier not to label as positive a sample that is negative\n",
    "        #\"recall\",       # The recall is intuitively the ability of the classifier to find all the positive samples.\n",
    "        ]\n",
    "    for score in scores:\n",
    "        log_hyperparameter_search(\"--- [%s] Running Parameter-Tests [POLY-SVC] ---\" % datetime.now())\n",
    "        log_hyperparameter_search(\"\\tTuning parameters for criteria [%s]\" % score)\n",
    "        # FIXME: Doesn't take accuracy as score for some reason. Refer to line below for accuracy score\n",
    "        #grid = GridSearchCV(estimator=svm, param_grid=parameters, scoring=\"%s_macro\" % score, verbose=3)\n",
    "        grid = GridSearchCV(estimator=svm, param_grid=parameters, scoring='accuracy', verbose=3, n_jobs=-1)\n",
    "        grid.fit(train_data, train_label)\n",
    "\n",
    "        log_hyperparameter_search(\"\\tBest parameters set found on following development set:\")\n",
    "        log_hyperparameter_search(\"\\t\\tSupport Vector: %s\" % grid.best_estimator_)\n",
    "        log_hyperparameter_search(\"\\t\\tSupport Vector Parametrization: %s\" % grid.best_params_)\n",
    "        log_hyperparameter_search(\"\\t\\tAsserted Score: %s\" % grid.best_score_)\n",
    "        log_hyperparameter_search(\"Total Score \\t\\t Configurations\")\n",
    "\n",
    "        means = grid.cv_results_[\"mean_test_score\"]\n",
    "        stds = grid.cv_results_[\"std_test_score\"]\n",
    "        params = grid.cv_results_[\"params\"]\n",
    "        for mean, std, params in zip(means, stds, params):\n",
    "            log_hyperparameter_search(\"%0.3f (+/-%0.03f)\\t%r\" % (mean, std, params))\n",
    "        print(\"Wrote classifier comparisons to file \", hyperparameter_search_log)\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\")\n",
    "    \n",
    "        y_true, y_pred = test_label, grid.predict(test_data)\n",
    "        log_hyperparameter_search(classification_report(y_true, y_pred))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBF SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained new model: {'Kernel':'rbf'} in 21.97466278076172 seconds\n",
      "\t[rbf]: mean accuracy on train-data: 0.9865324354956997; execution time: 55.52312421798706s\n",
      "\t[rbf]: mean accuracy on test-data: 0.9487795118047219; execution time: 7.668811559677124s\n"
     ]
    }
   ],
   "source": [
    "# Evalute SVM.SVC with parameters on data below\n",
    "svm = SVC(kernel='rbf')\n",
    "start_time = time.time()\n",
    "svm.fit(train_data, train_label)\n",
    "end_time = time.time() - start_time\n",
    "log_training_results(\"Trained new model: {'Kernel':'%s'} in %s seconds\" % (svm.get_params()[\"kernel\"], end_time))\n",
    "\n",
    "start_time = time.time()\n",
    "score = svm.score(train_data, train_label)\n",
    "end_time = time.time() - start_time\n",
    "log_training_results(\"\\t[%s]: mean accuracy on train-data: %s; execution time: %ss\" % (svm.get_params()[\"kernel\"], score, end_time))  \n",
    "\n",
    "start_time = time.time()\n",
    "score = svm.score(test_data, test_label)\n",
    "end_time = time.time() - start_time\n",
    "log_training_results(\"\\t[%s]: mean accuracy on test-data: %s; execution time: %ss\" % (svm.get_params()[\"kernel\"], score, end_time))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter search -- Takes up a long time.\n",
    "if config.hyper_parameter_search:\n",
    "    svm = SVC()\n",
    "    parameters = {\n",
    "            \"kernel\":[\"rbf\"], \n",
    "            \"C\":[1,10,50,100],            \n",
    "            \"gamma\":[0.01,0.005,0.001,0.0005,0.0001],        \n",
    "            #\"shrinking\":[True,False],      \n",
    "            #\"probability\":[True,False], \n",
    "            #\"tol\":[0.01,0.001,0.0001],\n",
    "    }\n",
    "    scores = [\n",
    "        \"accuracy\",\n",
    "        #\"precision\",    # The precision is intuitively the ability of the classifier not to label as positive a sample that is negative\n",
    "        #\"recall\",       # The recall is intuitively the ability of the classifier to find all the positive samples.\n",
    "        ]\n",
    "    for score in scores:\n",
    "        log_hyperparameter_search(\"--- [%s] Running Parameter-Tests [RBF-SVC] ---\" % datetime.now())\n",
    "        log_hyperparameter_search(\"\\tTuning parameters for criteria [%s]\" % score)\n",
    "        # FIXME: Doesn't take accuracy as score for some reason. Refer to line below for accuracy score\n",
    "        #grid = GridSearchCV(estimator=svm, param_grid=parameters, scoring=\"%s_macro\" % score, verbose=3)\n",
    "        grid = GridSearchCV(estimator=svm, param_grid=parameters, scoring='accuracy', verbose=3, n_jobs=-1)\n",
    "        grid.fit(train_data, train_label)\n",
    "\n",
    "        log_hyperparameter_search(\"\\tBest parameters set found on following development set:\")\n",
    "        log_hyperparameter_search(\"\\t\\tSupport Vector: %s\" % grid.best_estimator_)\n",
    "        log_hyperparameter_search(\"\\t\\tSupport Vector Parametrization: %s\" % grid.best_params_)\n",
    "        log_hyperparameter_search(\"\\t\\tAsserted Score: %s\" % grid.best_score_)\n",
    "        log_hyperparameter_search(\"Total Score \\t\\t Configurations\")\n",
    "\n",
    "        means = grid.cv_results_[\"mean_test_score\"]\n",
    "        stds = grid.cv_results_[\"std_test_score\"]\n",
    "        params = grid.cv_results_[\"params\"]\n",
    "        for mean, std, params in zip(means, stds, params):\n",
    "            log_hyperparameter_search(\"%0.3f (+/-%0.03f)\\t%r\" % (mean, std, params))\n",
    "        print(\"Wrote classifier comparisons to file \", hyperparameter_search_log)\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\")\n",
    "    \n",
    "        y_true, y_pred = test_label, grid.predict(test_data)\n",
    "        log_hyperparameter_search(classification_report(y_true, y_pred))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained new model: {'Kernel':'sigmoid'} in 19.1342294216156 seconds\n",
      "\t[sigmoid]: mean accuracy on train-data: 0.8052536835789053; execution time: 30.718257427215576s\n",
      "\t[sigmoid]: mean accuracy on test-data: 0.7911164465786314; execution time: 4.930406093597412s\n"
     ]
    }
   ],
   "source": [
    "# Evalute SVM.SVC with parameters on data below\n",
    "svm = SVC(kernel='sigmoid')\n",
    "start_time = time.time()\n",
    "svm.fit(train_data, train_label)\n",
    "end_time = time.time() - start_time\n",
    "log_training_results(\"Trained new model: {'Kernel':'%s'} in %s seconds\" % (svm.get_params()[\"kernel\"], end_time))\n",
    "\n",
    "start_time = time.time()\n",
    "score = svm.score(train_data, train_label)\n",
    "end_time = time.time() - start_time\n",
    "log_training_results(\"\\t[%s]: mean accuracy on train-data: %s; execution time: %ss\" % (svm.get_params()[\"kernel\"], score, end_time))  \n",
    "\n",
    "start_time = time.time()\n",
    "score = svm.score(test_data, test_label)\n",
    "end_time = time.time() - start_time\n",
    "log_training_results(\"\\t[%s]: mean accuracy on test-data: %s; execution time: %ss\" % (svm.get_params()[\"kernel\"], score, end_time))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter search -- Takes up a long time.\n",
    "if config.hyper_parameter_search:\n",
    "    svm = SVC()\n",
    "    parameters = {\n",
    "            \"kernel\":[\"sigmoid\"], \n",
    "            \"C\":[1,10,50,100],            \n",
    "            \"gamma\":[0.01,0.005,0.001,0.0005,0.0001],        \n",
    "            #\"shrinking\":[True,False],      \n",
    "            #\"probability\":[True,False], \n",
    "            #\"tol\":[0.01,0.001,0.0001],\n",
    "    }\n",
    "    scores = [\n",
    "        \"accuracy\",\n",
    "        #\"precision\",    # The precision is intuitively the ability of the classifier not to label as positive a sample that is negative\n",
    "        #\"recall\",       # The recall is intuitively the ability of the classifier to find all the positive samples.\n",
    "        ]\n",
    "    for score in scores:\n",
    "        log_hyperparameter_search(\"--- [%s] Running Parameter-Tests [Sigmoid-SVC] ---\" % datetime.now())\n",
    "        log_hyperparameter_search(\"\\tTuning parameters for criteria [%s]\" % score)\n",
    "        # FIXME: Doesn't take accuracy as score for some reason. Refer to line below for accuracy score\n",
    "        #grid = GridSearchCV(estimator=svm, param_grid=parameters, scoring=\"%s_macro\" % score, verbose=3)\n",
    "        grid = GridSearchCV(estimator=svm, param_grid=parameters, scoring='accuracy', verbose=3, n_jobs=-1)\n",
    "        grid.fit(train_data, train_label)\n",
    "\n",
    "        log_hyperparameter_search(\"\\tBest parameters set found on following development set:\")\n",
    "        log_hyperparameter_search(\"\\t\\tSupport Vector: %s\" % grid.best_estimator_)\n",
    "        log_hyperparameter_search(\"\\t\\tSupport Vector Parametrization: %s\" % grid.best_params_)\n",
    "        log_hyperparameter_search(\"\\t\\tAsserted Score: %s\" % grid.best_score_)\n",
    "        log_hyperparameter_search(\"Total Score \\t\\t Configurations\")\n",
    "\n",
    "        means = grid.cv_results_[\"mean_test_score\"]\n",
    "        stds = grid.cv_results_[\"std_test_score\"]\n",
    "        params = grid.cv_results_[\"params\"]\n",
    "        for mean, std, params in zip(means, stds, params):\n",
    "            log_hyperparameter_search(\"%0.3f (+/-%0.03f)\\t%r\" % (mean, std, params))\n",
    "        print(\"Wrote classifier comparisons to file \", hyperparameter_search_log)\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\")\n",
    "    \n",
    "        y_true, y_pred = test_label, grid.predict(test_data)\n",
    "        log_hyperparameter_search(classification_report(y_true, y_pred))\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e2b2785e650337f79381cd4c5df08c4d5dc4623a6a0d2da7e01465b331d0fcc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
