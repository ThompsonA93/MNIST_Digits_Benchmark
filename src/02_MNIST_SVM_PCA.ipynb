{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST-SVM-PCA\n",
    "\n",
    "The following script executes a program for digit recognition on the mnist database using Support Vector Machines (SVM) and Principal Component Analysis (PCA). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Packages\n",
    "from datetime import datetime\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.datasets import mnist\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "### Configurations\n",
    "# Training-Size\n",
    "num_train = 15000                   # 60000 for full data set \n",
    "num_test  = 2500                    # 10000 for full data set\n",
    "\n",
    "# Use GridSearchCV to look up optimal parameters (see below)\n",
    "hyper_parameter_search = False       # True/False: Run hyper-parameter search via GridSearchCV. Takes a long time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple function to log information\n",
    "txt_out_file_path = 'svm-hyperparameter-tuning-log.txt'\n",
    "def print_to_txt_file(*s):\n",
    "    with open(txt_out_file_path, 'a') as f:\n",
    "        for arg in s:\n",
    "            print(arg, file=f)\n",
    "            print(arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch MNIST-Data from Keras repository\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display (Train) (Test) datasets\n",
    "print(\"Data : Dataset Trainingset\")\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(\"Labels : Dataset Trainingset\")\n",
    "print(y_train.shape, y_test.shape)\n",
    "\n",
    "# i.e.: We have 60000 images with a size of 28x28 pixels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some examples\n",
    "num_classes = 10 # 0 .. 9\n",
    "f, ax = plt.subplots(1, num_classes, figsize=(20,20))\n",
    "for i in range(0, num_classes):\n",
    "  sample = X_train[y_train == i][0]\n",
    "  ax[i].imshow(sample, cmap='gray')\n",
    "  ax[i].set_title(\"Label: {}\".format(i), fontsize=16)\n",
    "  ax[i].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare loaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data such that we have access to every pixel of the image\n",
    "# The reason to access every pixel is that only then we can apply deep learning ideas and can assign color code to every pixel.\n",
    "train_data = X_train.reshape((X_train.shape[0], 28*28)).astype('float32')\n",
    "train_label = y_train.astype(\"float32\")\n",
    "\n",
    "test_data = X_test.reshape((X_test.shape[0], 28*28)).astype('float32')\n",
    "test_label = y_test.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We know the RGB color code where different values produce various colors. It is also difficult to remember every color combination. \n",
    "# We already know that each pixel has its unique color code and also we know that it has a maximum value of 255. \n",
    "# To perform Machine Learning, it is important to convert all the values from 0 to 255 for every pixel to a range of values from 0 to 1.\n",
    "train_data = train_data / 255\n",
    "test_data = test_data / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As an optional step, we decrease the training and testing data size, such that the algorithms perform their execution in acceptable time\n",
    "train_data = train_data[1:num_train,]\n",
    "train_label = train_label[1:num_train]\n",
    "\n",
    "test_data = test_data[1:num_test,]\n",
    "test_label = test_label[1:num_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display (Train) (Test) datasets\n",
    "print(\"Reshaped Data : Dataset Trainingset\")\n",
    "print(train_data.shape, test_data.shape)\n",
    "print(\"Reshaped Labels : Dataset Trainingset\")\n",
    "print(train_label.shape, test_label.shape)\n",
    "\n",
    "# As we can see: We now have X images with 784 pixels in total\n",
    "# We now operate on this data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component Analysis\n",
    "\n",
    "Linear dimensionality reduction using Singular Value Decomposition of the data to project it to a lower dimensional space. The input data is centered but not scaled for each feature before applying the SVD.\n",
    "It uses the LAPACK implementation of the full SVD or a randomized truncated SVD by the method of Halko et al. 2009, depending on the shape of the input data and the number of components to extract.\n",
    "\n",
    "For more information, see: https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The default layout of PCA()\n",
    "# @see https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\n",
    "pca = PCA(\n",
    "    n_components=None,                  # Number of components to keep. if n_components is not set all components are kept\n",
    "    copy=True,                          # If False, data passed to fit are overwritten and running fit(X).transform(X) will not yield the expected results, use fit_transform(X) instead.\n",
    "    whiten=False,                       # Whitening will remove some information from the transformed signal (the relative variance scales of the components) but can sometime improve the predictive accuracy of the downstream estimators by making their data respect some hard-wired assumptions.\n",
    "    svd_solver='auto',                  # The solver is selected by a default policy based on X.shape and n_components: if the input data is larger than 500x500 and the number of components to extract is lower than 80% of the smallest dimension of the data, then the more efficient ‘randomized’ method is enabled. Otherwise the exact full SVD is computed and optionally truncated afterwards.\n",
    "    tol=0.0,                            # Tolerance for singular values computed by svd_solver == ‘arpack’. Must be of range [0.0, infinity).\n",
    "    iterated_power='auto',              # Number of iterations for the power method computed by svd_solver == ‘randomized’. Must be of range [0, infinity).\n",
    "    n_oversamples=10,                   # This parameter is only relevant when svd_solver=\"randomized\". It corresponds to the additional number of random vectors to sample the range of X so as to ensure proper conditioning.\n",
    "    power_iteration_normalizer='auto',  # Power iteration normalizer for randomized SVD solver. Not used by ARPACK. See randomized_svd for more details.\n",
    "    random_state=None                   # Used when the ‘arpack’ or ‘randomized’ solvers are used. Pass an int for reproducible results across multiple function calls. \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the PCA algorithm with the datasets\n",
    "pca = PCA(\n",
    "    n_components=None, \n",
    "    copy=True, \n",
    "    whiten=False, \n",
    "    svd_solver='auto', \n",
    "    tol=0.0, \n",
    "    iterated_power='auto', \n",
    "    n_oversamples=10, \n",
    "    power_iteration_normalizer='auto', \n",
    "    random_state=None\n",
    ")\n",
    "pca.fit(train_data, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping the data based on the PCA\n",
    "pca_train_data = pca.transform(train_data)\n",
    "pca_test_data = pca.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines\n",
    "\n",
    "Support vector machines (SVMs) are a set of supervised learning methods used for classification, regression and outliers detection. We use the SVM-package supplied by SKLearn.\n",
    "\n",
    "For more information, see: https://scikit-learn.org/stable/modules/svm.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The default layout of svm.svc() \n",
    "# @see https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "svm = SVC(\n",
    "    C=1.0,                          # Regularization parameter. The strength of the regularization is inversely proportional to C. Must be strictly positive. The penalty is a squared l2 penalty.\n",
    "    kernel='linear',                # Specifies the kernel type to be used in the algorithm. \n",
    "    degree=3,                       # Degree of the polynomial kernel function (‘poly’). Ignored by all other kernels.\n",
    "    gamma='scale',                  # Kernel coefficient for ‘rbf’, ‘poly’ and ‘sigmoid’.\n",
    "    coef0=0.0,                      # Independent term in kernel function. It is only significant in ‘poly’ and ‘sigmoid’.\n",
    "    shrinking=True,                 # Whether to use the shrinking heuristic. \n",
    "    probability=False,              # Whether to enable probability estimates. \n",
    "    tol=0.001,                      # Tolerance for stopping criterion.\n",
    "    cache_size=200,                 # Specify the size of the kernel cache (in MB).\n",
    "    class_weight=None,              # Set the parameter C of class i to class_weight[i]*C for SVC. If not given, all classes are supposed to have weight one. \n",
    "    verbose=False,                  # Enable verbose output. Note that this setting takes advantage of a per-process runtime setting in libsvm that, if enabled, may not work properly in a multithreaded context.\n",
    "    max_iter=-1,                    # Hard limit on iterations within solver, or -1 for no limit.\n",
    "    decision_function_shape='ovr',  # Whether to return a one-vs-rest (‘ovr’) decision function of shape (n_samples, n_classes) as all other classifiers, or the original one-vs-one (‘ovo’) decision function of libsvm which has shape (n_samples, n_classes * (n_classes - 1) / 2).\n",
    "    break_ties=False,               # If true, decision_function_shape='ovr', and number of classes > 2, predict will break ties according to the confidence values of decision_function;\n",
    "    random_state=None               # Controls the pseudo random number generation for shuffling the data for probability estimates.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evalute SVM.SVC with parameters on data below\n",
    "svm = SVC(\n",
    "    C=1.0, \n",
    "    kernel='linear', \n",
    "    degree=3, \n",
    "    gamma='scale', \n",
    "    coef0=0.0, \n",
    "    shrinking=True, \n",
    "    probability=False, \n",
    "    tol=0.001, \n",
    "    cache_size=200, \n",
    "    class_weight=None,\n",
    "    verbose=False, \n",
    "    max_iter=-1, \n",
    "    decision_function_shape='ovr', \n",
    "    break_ties=False, \n",
    "    random_state=None    \n",
    ")\n",
    "svm.fit(pca_train_data, train_label)\n",
    "print(\"Mean accuracy on train data: \", svm.score(train_data, train_label))   # Mean Accuracy on the given training data and labels\n",
    "print(\"Mean accuracy on test data: \", svm.score(test_data, test_label))      # Mean Accuracy on the given test data and labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter search -- Takes up a long time.\n",
    "if hyper_parameter_search:\n",
    "    svm = SVC()\n",
    "    parameters = {\n",
    "            \"kernel\":[\"linear\"], \n",
    "            \"C\":[1,10,100],                \n",
    "            \"shrinking\":[True,False],      \n",
    "            \"probability\":[True,False], \n",
    "            \"tol\":[0.01,0.001,0.0001],\n",
    "    }\n",
    "    scores = [\n",
    "        'accuracy',\n",
    "        #\"precision\",    # The precision is intuitively the ability of the classifier not to label as positive a sample that is negative\n",
    "        #\"recall\",       # The recall is intuitively the ability of the classifier to find all the positive samples.\n",
    "        ]\n",
    "    for score in scores:\n",
    "        print_to_txt_file(\"--- [%s] Running Parameter-Tests [LINEAR-SVC] ---\" % datetime.now())\n",
    "        print_to_txt_file(\"Tuning parameters for criteria [%s]\" % score)\n",
    "        # FIXME: Doesn't take accuracy as score for some reason. Refer to line below for accuracy score\n",
    "        #grid = GridSearchCV(estimator=svm, param_grid=parameters, scoring=\"%s_macro\" % score, verbose=3)\n",
    "        grid = GridSearchCV(estimator=svm, param_grid=parameters, scoring='accuracy', verbose=3)\n",
    "        grid.fit(pca_train_data, train_label)\n",
    "\n",
    "        print_to_txt_file(\"Best parameters set found on following development set:\")\n",
    "        print_to_txt_file(\"\\tSupport Vector: %s\" % grid.best_estimator_)\n",
    "        print_to_txt_file(\"\\tSupport Vector Parametrization: %s\" % grid.best_params_)\n",
    "        print_to_txt_file(\"\\tAsserted Score: %s\" % grid.best_score_)\n",
    "        print_to_txt_file(\"Total Score \\t\\t Configurations\")\n",
    "\n",
    "        means = grid.cv_results_[\"mean_test_score\"]\n",
    "        stds = grid.cv_results_[\"std_test_score\"]\n",
    "        params = grid.cv_results_[\"params\"]\n",
    "        for mean, std, params in zip(means, stds, params):\n",
    "            print_to_txt_file(\"%0.3f (+/-%0.03f)\\t%r\" % (mean, std, params))\n",
    "        print(\"Wrote classifier comparisons to file \", txt_out_file_path)\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\")\n",
    "    \n",
    "        y_true, y_pred = test_label, grid.predict(test_data)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poly SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evalute SVM.SVC with parameters on data below\n",
    "svm = SVC(\n",
    "    C=1.0, \n",
    "    kernel='poly', \n",
    "    degree=3, \n",
    "    gamma='scale', \n",
    "    coef0=0.0, \n",
    "    shrinking=True, \n",
    "    probability=False, \n",
    "    tol=0.001, \n",
    "    cache_size=200, \n",
    "    class_weight=None,\n",
    "    verbose=False, \n",
    "    max_iter=-1, \n",
    "    decision_function_shape='ovr', \n",
    "    break_ties=False, \n",
    "    random_state=None    \n",
    ")\n",
    "svm.fit(pca_train_data, train_label)\n",
    "print(\"Mean accuracy on train data: \", svm.score(train_data, train_label))   # Mean Accuracy on the given training data and labels\n",
    "print(\"Mean accuracy on test data: \", svm.score(test_data, test_label))      # Mean Accuracy on the given test data and labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter search -- Takes up a long time.\n",
    "if hyper_parameter_search:\n",
    "    svm = SVC()\n",
    "    parameters = {\n",
    "            \"kernel\":[\"poly\"], \n",
    "            \"C\":[1,10,100],\n",
    "            \"gamma\":[\"scale\", \"auto\"],\n",
    "            \"coef0\":[0.0, 0.5],\n",
    "            \"degree\":[3,5,10],                \n",
    "            \"shrinking\":[True,False],      \n",
    "            \"probability\":[True,False], \n",
    "            \"tol\":[0.01,0.001,0.0001],\n",
    "    }\n",
    "    scores = [\n",
    "        \"accuracy\",\n",
    "        #\"precision\",    # The precision is intuitively the ability of the classifier not to label as positive a sample that is negative\n",
    "        #\"recall\",       # The recall is intuitively the ability of the classifier to find all the positive samples.\n",
    "        ]\n",
    "    for score in scores:\n",
    "        print_to_txt_file(\"--- [%s] Running Parameter-Tests [POLY-SVC] ---\" % datetime.now())\n",
    "        print_to_txt_file(\"Tuning parameters for criteria [%s]\" % score)\n",
    "        # FIXME: Doesn't take accuracy as score for some reason. Refer to line below for accuracy score\n",
    "        # grid = GridSearchCV(estimator=svm, param_grid=parameters, scoring=\"%s_macro\" % score, verbose=3)\n",
    "        grid = GridSearchCV(estimator=svm, param_grid=parameters, scoring='accuracy', verbose=3)\n",
    "        grid.fit(pca_train_data, train_label)\n",
    "\n",
    "        print_to_txt_file(\"Best parameters set found on following development set:\")\n",
    "        print_to_txt_file(\"\\tSupport Vector: %s\" % grid.best_estimator_)\n",
    "        print_to_txt_file(\"\\tSupport Vector Parametrization: %s\" % grid.best_params_)\n",
    "        print_to_txt_file(\"\\tAsserted Score: %s\" % grid.best_score_)\n",
    "        print_to_txt_file(\"Total Score \\t\\t Configurations\")\n",
    "\n",
    "        means = grid.cv_results_[\"mean_test_score\"]\n",
    "        stds = grid.cv_results_[\"std_test_score\"]\n",
    "        params = grid.cv_results_[\"params\"]\n",
    "        for mean, std, params in zip(means, stds, params):\n",
    "            print_to_txt_file(\"%0.3f (+/-%0.03f)\\t%r\" % (mean, std, params))\n",
    "        print(\"Wrote classifier comparisons to file \", txt_out_file_path)\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\")\n",
    "    \n",
    "        y_true, y_pred = test_label, grid.predict(test_data)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBF SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evalute SVM.SVC with parameters on data below\n",
    "svm = SVC(\n",
    "    C=1.0, \n",
    "    kernel='rbf', \n",
    "    degree=3, \n",
    "    gamma='scale', \n",
    "    coef0=0.0, \n",
    "    shrinking=True, \n",
    "    probability=False, \n",
    "    tol=0.001, \n",
    "    cache_size=200, \n",
    "    class_weight=None,\n",
    "    verbose=False, \n",
    "    max_iter=-1, \n",
    "    decision_function_shape='ovr', \n",
    "    break_ties=False, \n",
    "    random_state=None    \n",
    ")\n",
    "svm.fit(pca_train_data, train_label)\n",
    "print(\"Mean accuracy on train data: \", svm.score(train_data, train_label))   # Mean Accuracy on the given training data and labels\n",
    "print(\"Mean accuracy on test data: \", svm.score(test_data, test_label))      # Mean Accuracy on the given test data and labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter search -- Takes up a long time.\n",
    "if hyper_parameter_search:\n",
    "    svm = SVC()\n",
    "    parameters = {\n",
    "            \"kernel\":[\"rbf\"], \n",
    "            \"C\":[1,10,100],           \n",
    "            \"gamma\":[\"scale\", \"auto\"],     \n",
    "            \"shrinking\":[True,False],      \n",
    "            \"probability\":[True,False], \n",
    "            \"tol\":[0.01,0.001,0.0001],\n",
    "    }\n",
    "    scores = [\n",
    "        \"accuracy\",\n",
    "        #\"precision\",    # The precision is intuitively the ability of the classifier not to label as positive a sample that is negative\n",
    "        #\"recall\",       # The recall is intuitively the ability of the classifier to find all the positive samples.\n",
    "        ]\n",
    "    for score in scores:\n",
    "        print_to_txt_file(\"--- [%s] Running Parameter-Tests [RBF-SVC] ---\" % datetime.now())\n",
    "        print_to_txt_file(\"Tuning parameters for criteria [%s]\" % score)\n",
    "        # FIXME: Doesn't take accuracy as score for some reason. Refer to line below for accuracy score\n",
    "        #grid = GridSearchCV(estimator=svm, param_grid=parameters, scoring=\"%s_macro\" % score, verbose=3)\n",
    "        grid = GridSearchCV(estimator=svm, param_grid=parameters, scoring='accuracy', verbose=3)\n",
    "        grid.fit(pca_train_data, train_label)\n",
    "\n",
    "        print_to_txt_file(\"Best parameters set found on following development set:\")\n",
    "        print_to_txt_file(\"\\tSupport Vector: %s\" % grid.best_estimator_)\n",
    "        print_to_txt_file(\"\\tSupport Vector Parametrization: %s\" % grid.best_params_)\n",
    "        print_to_txt_file(\"\\tAsserted Score: %s\" % grid.best_score_)\n",
    "        print_to_txt_file(\"Total Score \\t\\t Configurations\")\n",
    "\n",
    "        means = grid.cv_results_[\"mean_test_score\"]\n",
    "        stds = grid.cv_results_[\"std_test_score\"]\n",
    "        params = grid.cv_results_[\"params\"]\n",
    "        for mean, std, params in zip(means, stds, params):\n",
    "            print_to_txt_file(\"%0.3f (+/-%0.03f)\\t%r\" % (mean, std, params))\n",
    "        print(\"Wrote classifier comparisons to file \", txt_out_file_path)\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\")\n",
    "    \n",
    "        y_true, y_pred = test_label, grid.predict(test_data)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evalute SVM.SVC with parameters on data below\n",
    "svm = SVC(\n",
    "    C=1.0, \n",
    "    kernel='sigmoid', \n",
    "    degree=3, \n",
    "    gamma='scale', \n",
    "    coef0=0.0, \n",
    "    shrinking=True, \n",
    "    probability=False, \n",
    "    tol=0.001, \n",
    "    cache_size=200, \n",
    "    class_weight=None,\n",
    "    verbose=False, \n",
    "    max_iter=-1, \n",
    "    decision_function_shape='ovr', \n",
    "    break_ties=False, \n",
    "    random_state=None    \n",
    ")\n",
    "svm.fit(pca_train_data, train_label)\n",
    "print(\"Mean accuracy on train data: \", svm.score(train_data, train_label))   # Mean Accuracy on the given training data and labels\n",
    "print(\"Mean accuracy on test data: \", svm.score(test_data, test_label))      # Mean Accuracy on the given test data and labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter search -- Takes up a long time.\n",
    "if hyper_parameter_search:\n",
    "    svm = SVC()\n",
    "    parameters = {\n",
    "            \"kernel\":[\"sigmoid\"], \n",
    "            \"C\":[1,10,100],           \n",
    "            \"gamma\":[\"scale\", \"auto\"],     \n",
    "            \"shrinking\":[True,False],      \n",
    "            \"probability\":[True,False], \n",
    "            \"tol\":[0.01,0.001,0.0001],\n",
    "    }\n",
    "    scores = [\n",
    "        \"accuracy\",\n",
    "        #\"precision\",    # The precision is intuitively the ability of the classifier not to label as positive a sample that is negative\n",
    "        #\"recall\",       # The recall is intuitively the ability of the classifier to find all the positive samples.\n",
    "        ]\n",
    "    for score in scores:\n",
    "        print_to_txt_file(\"--- [%s] Running Parameter-Tests [SIGMOID-SVC] ---\" % datetime.now())\n",
    "        print_to_txt_file(\"Tuning parameters for criteria [%s]\" % score)\n",
    "        # FIXME: Doesn't take accuracy as score for some reason. Refer to line below for accuracy score\n",
    "        #grid = GridSearchCV(estimator=svm, param_grid=parameters, scoring=\"%s_macro\" % score, verbose=3)\n",
    "        grid = GridSearchCV(estimator=svm, param_grid=parameters, scoring='accuracy', verbose=3)\n",
    "        grid.fit(pca_train_data, train_label)\n",
    "\n",
    "        print_to_txt_file(\"Best parameters set found on following development set:\")\n",
    "        print_to_txt_file(\"\\tSupport Vector: %s\" % grid.best_estimator_)\n",
    "        print_to_txt_file(\"\\tSupport Vector Parametrization: %s\" % grid.best_params_)\n",
    "        print_to_txt_file(\"\\tAsserted Score: %s\" % grid.best_score_)\n",
    "        print_to_txt_file(\"Total Score \\t\\t Configurations\")\n",
    "\n",
    "        means = grid.cv_results_[\"mean_test_score\"]\n",
    "        stds = grid.cv_results_[\"std_test_score\"]\n",
    "        params = grid.cv_results_[\"params\"]\n",
    "        for mean, std, params in zip(means, stds, params):\n",
    "            print_to_txt_file(\"%0.3f (+/-%0.03f)\\t%r\" % (mean, std, params))\n",
    "        print(\"Wrote classifier comparisons to file \", txt_out_file_path)\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\")\n",
    "    \n",
    "        y_true, y_pred = test_label, grid.predict(test_data)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e2b2785e650337f79381cd4c5df08c4d5dc4623a6a0d2da7e01465b331d0fcc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
