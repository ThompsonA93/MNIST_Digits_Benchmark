{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST-SVM-PCA\n",
    "\n",
    "The following script executes a program for digit recognition on the mnist database using Support Vector Machines (SVM) and Principal Component Analysis (PCA). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Packages\n",
    "from datetime import datetime\n",
    "import time\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import config\n",
    "\n",
    "### Configurations\n",
    "# Training-Size\n",
    "num_train = config.num_train                   # 60000 for full data set \n",
    "num_test  = config.num_test                    # 10000 for full data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated data will be located in  c:\\Users\\auerth\\Desktop\\Study\\MNIST_Digits_Benchmark\\src/log/svm-pca-training-log.txt c:\\Users\\auerth\\Desktop\\Study\\MNIST_Digits_Benchmark\\src/log/svm-pca-hyperparameter-tuning-log.txt\n",
      "[2022-09-12 15:57:43.343515] on (Windows-10-10.0.19044-SP0, Intel64 Family 6 Model 140 Stepping 1, GenuineIntel) using (Train: 15000, Test: 2500)\n"
     ]
    }
   ],
   "source": [
    "# Simple function to log information\n",
    "path = os.getcwd()+\"/log\"\n",
    "logDir = os.path.exists(path)\n",
    "if not logDir:\n",
    "    os.makedirs(path)\n",
    "\n",
    "training_results = path+\"/svm-pca-training-log.txt\"\n",
    "def log_training_results(*s):\n",
    "    with open(training_results, 'a') as f:\n",
    "        for arg in s:\n",
    "            print(arg, file=f)\n",
    "            print(arg)\n",
    "\n",
    "hyperparameter_search_log = path+\"/svm-pca-hyperparameter-tuning-log.txt\"\n",
    "def log_hyperparameter_search(*s):\n",
    "    with open(hyperparameter_search_log, 'a') as f:\n",
    "        for arg in s:\n",
    "            print(arg, file=f)\n",
    "            print(arg)\n",
    "\n",
    "print(\"Generated data will be located in \", training_results, hyperparameter_search_log)\n",
    "log_training_results(\"[%s] on (%s, %s) using (Train: %s, Test: %s)\" % (datetime.now(), config.os, config.cpu, config.num_train, config.num_test))\n",
    "if config.hyper_parameter_search:\n",
    "    log_hyperparameter_search(\"[%s] on (%s, %s) using (Train: %s, Test: %s)\" % (datetime.now(), config.os, config.cpu, config.num_train, config.num_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch MNIST-Data from Keras repository\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data:\t\t (60000, 28, 28)\n",
      "Shape of training labels:\t (60000,)\n",
      "Shape of testing data:\t\t (10000, 28, 28)\n",
      "Shape of testing labels:\t (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Display (Train) (Test) datasets\n",
    "print(\"Shape of training data:\\t\\t\", X_train.shape)\n",
    "print(\"Shape of training labels:\\t\", y_train.shape)\n",
    "print(\"Shape of testing data:\\t\\t\", X_test.shape)\n",
    "print(\"Shape of testing labels:\\t\", y_test.shape)\n",
    "\n",
    "# i.e.: We have 60000 images with a size of 28x28 pixels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x2000 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize some examples\n",
    "num_classes = 10 # 0 .. 9\n",
    "f, ax = plt.subplots(1, num_classes, figsize=(20,20))\n",
    "for i in range(0, num_classes):\n",
    "  sample = X_train[y_train == i][0]\n",
    "  ax[i].imshow(sample, cmap='gray')\n",
    "  ax[i].set_title(\"Label: {}\".format(i), fontsize=16)\n",
    "  ax[i].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare loaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data such that we have access to every pixel of the image\n",
    "# The reason to access every pixel is that only then we can apply deep learning ideas and can assign color code to every pixel.\n",
    "\n",
    "train_data = X_train.reshape((X_train.shape[0], 28*28)).astype('float32')\n",
    "train_label = y_train.astype(\"float32\")\n",
    "\n",
    "test_data = X_test.reshape((X_test.shape[0], 28*28)).astype('float32')\n",
    "test_label = y_test.astype(\"float32\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We know the RGB color code where different values produce various colors. It is also difficult to remember every color combination. \n",
    "# We already know that each pixel has its unique color code and also we know that it has a maximum value of 255. \n",
    "# To perform Machine Learning, it is important to convert all the values from 0 to 255 for every pixel to a range of values from 0 to 1.\n",
    "train_data = train_data / 255\n",
    "test_data = test_data / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As an optional step, we decrease the training and testing data size, such that the algorithms perform their execution in acceptable time\n",
    "train_data = train_data[1:num_train,]\n",
    "train_label = train_label[1:num_train]\n",
    "\n",
    "test_data = test_data[1:num_test,]\n",
    "test_label = test_label[1:num_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped training data:\t\t (14999, 784)\n",
      "Reshaped training labels:\t (14999,)\n",
      "Reshaped testing data:\t\t (2499, 784)\n",
      "Reshaped testing labels:\t (2499,)\n"
     ]
    }
   ],
   "source": [
    "# Display (Train) (Test) datasets\n",
    "\n",
    "print(\"Reshaped training data:\\t\\t\", train_data.shape)\n",
    "print(\"Reshaped training labels:\\t\", train_label.shape)\n",
    "print(\"Reshaped testing data:\\t\\t\", test_data.shape)\n",
    "print(\"Reshaped testing labels:\\t\", test_label.shape)\n",
    "\n",
    "# As we can see: We now have X images with 784 pixels in total\n",
    "# We now operate on this data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component Analysis\n",
    "\n",
    "Linear dimensionality reduction using Singular Value Decomposition of the data to project it to a lower dimensional space. The input data is centered but not scaled for each feature before applying the SVD.\n",
    "It uses the LAPACK implementation of the full SVD or a randomized truncated SVD by the method of Halko et al. 2009, depending on the shape of the input data and the number of components to extract.\n",
    "\n",
    "For more information, see: https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The default layout of PCA()\n",
    "# @see https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\n",
    "pca = PCA(\n",
    "    n_components=None,                  # Number of components to keep. if n_components is not set all components are kept\n",
    "    copy=True,                          # If False, data passed to fit are overwritten and running fit(X).transform(X) will not yield the expected results, use fit_transform(X) instead.\n",
    "    whiten=False,                       # Whitening will remove some information from the transformed signal (the relative variance scales of the components) but can sometime improve the predictive accuracy of the downstream estimators by making their data respect some hard-wired assumptions.\n",
    "    svd_solver='auto',                  # The solver is selected by a default policy based on X.shape and n_components: if the input data is larger than 500x500 and the number of components to extract is lower than 80% of the smallest dimension of the data, then the more efficient ‘randomized’ method is enabled. Otherwise the exact full SVD is computed and optionally truncated afterwards.\n",
    "    tol=0.0,                            # Tolerance for singular values computed by svd_solver == ‘arpack’. Must be of range [0.0, infinity).\n",
    "    iterated_power='auto',              # Number of iterations for the power method computed by svd_solver == ‘randomized’. Must be of range [0, infinity).\n",
    "    n_oversamples=10,                   # This parameter is only relevant when svd_solver=\"randomized\". It corresponds to the additional number of random vectors to sample the range of X so as to ensure proper conditioning.\n",
    "    power_iteration_normalizer='auto',  # Power iteration normalizer for randomized SVD solver. Not used by ARPACK. See randomized_svd for more details.\n",
    "    random_state=None                   # Used when the ‘arpack’ or ‘randomized’ solvers are used. Pass an int for reproducible results across multiple function calls. \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the PCA algorithm with the datasets\n",
    "pca = PCA().fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping the data based on the PCA\n",
    "pca_train_data = pca.transform(train_data)\n",
    "pca_test_data = pca.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped training data:\t\t (14999, 784)\n",
      "Reshaped training labels:\t (14999,)\n",
      "Reshaped testing data:\t\t (2499, 784)\n",
      "Reshaped testing labels:\t (2499,)\n"
     ]
    }
   ],
   "source": [
    "# Display (Train) (Test) datasets\n",
    "\n",
    "print(\"Reshaped training data:\\t\\t\", pca_train_data.shape)\n",
    "print(\"Reshaped training labels:\\t\", train_label.shape)\n",
    "print(\"Reshaped testing data:\\t\\t\", pca_test_data.shape)\n",
    "print(\"Reshaped testing labels:\\t\", test_label.shape)\n",
    "\n",
    "# As we can see: We now have X images with 784 pixels in total\n",
    "# We now operate on this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(pca.explained_variance_ratio_, log=True)\n",
    "pca.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines\n",
    "\n",
    "Support vector machines (SVMs) are a set of supervised learning methods used for classification, regression and outliers detection. We use the SVM-package supplied by SKLearn.\n",
    "\n",
    "For more information, see: https://scikit-learn.org/stable/modules/svm.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The default layout of svm.svc() \n",
    "# @see https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "svm = SVC(\n",
    "    C=1.0,                          # Regularization parameter. The strength of the regularization is inversely proportional to C. Must be strictly positive. The penalty is a squared l2 penalty.\n",
    "    kernel='linear',                # Specifies the kernel type to be used in the algorithm. \n",
    "    degree=3,                       # Degree of the polynomial kernel function (‘poly’). Ignored by all other kernels.\n",
    "    gamma='scale',                  # Kernel coefficient for ‘rbf’, ‘poly’ and ‘sigmoid’.\n",
    "    coef0=0.0,                      # Independent term in kernel function. It is only significant in ‘poly’ and ‘sigmoid’.\n",
    "    shrinking=True,                 # Whether to use the shrinking heuristic. \n",
    "    probability=False,              # Whether to enable probability estimates. \n",
    "    tol=0.001,                      # Tolerance for stopping criterion.\n",
    "    cache_size=200,                 # Specify the size of the kernel cache (in MB).\n",
    "    class_weight=None,              # Set the parameter C of class i to class_weight[i]*C for SVC. If not given, all classes are supposed to have weight one. \n",
    "    verbose=False,                  # Enable verbose output. Note that this setting takes advantage of a per-process runtime setting in libsvm that, if enabled, may not work properly in a multithreaded context.\n",
    "    max_iter=-1,                    # Hard limit on iterations within solver, or -1 for no limit.\n",
    "    decision_function_shape='ovr',  # Whether to return a one-vs-rest (‘ovr’) decision function of shape (n_samples, n_classes) as all other classifiers, or the original one-vs-one (‘ovo’) decision function of libsvm which has shape (n_samples, n_classes * (n_classes - 1) / 2).\n",
    "    break_ties=False,               # If true, decision_function_shape='ovr', and number of classes > 2, predict will break ties according to the confidence values of decision_function;\n",
    "    random_state=None               # Controls the pseudo random number generation for shuffling the data for probability estimates.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained new model: {'Kernel':'linear'} in 12.408801078796387 seconds\n",
      "\t[linear]: mean accuracy on train-data: 0.9921328088539236; execution time: 17.622085094451904s\n",
      "\t[linear]: mean accuracy on test-data: 0.8935574229691877; execution time: 2.831554412841797s\n"
     ]
    }
   ],
   "source": [
    "# Evalute SVM.SVC with parameters on data below\n",
    "svm = SVC(kernel='linear')\n",
    "start_time = time.time()\n",
    "svm.fit(pca_train_data, train_label)\n",
    "end_time = time.time() - start_time\n",
    "log_training_results(\"Trained new model: {'Kernel':'%s'} in %s seconds\" % (svm.get_params()[\"kernel\"], end_time))\n",
    "\n",
    "start_time = time.time()\n",
    "score = svm.score(pca_train_data, train_label)\n",
    "end_time = time.time() - start_time\n",
    "log_training_results(\"\\t[%s]: mean accuracy on train-data: %s; execution time: %ss\" % (svm.get_params()[\"kernel\"], score, end_time))  \n",
    "\n",
    "start_time = time.time()\n",
    "score = svm.score(pca_test_data, test_label)\n",
    "end_time = time.time() - start_time\n",
    "log_training_results(\"\\t[%s]: mean accuracy on test-data: %s; execution time: %ss\" % (svm.get_params()[\"kernel\"], score, end_time))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter search -- Takes up a long time.\n",
    "if config.hyper_parameter_search:\n",
    "    svm = SVC()\n",
    "    parameters = {\n",
    "            \"kernel\":[\"linear\"], \n",
    "            \"C\":[1,10,100],            \n",
    "            \"gamma\":[0.01,0.005,0.001,0.0005,0.0001],        \n",
    "            #\"shrinking\":[True,False],      \n",
    "            #\"probability\":[True,False], \n",
    "            #\"tol\":[0.01,0.001,0.0001],\n",
    "    }\n",
    "    scores = [\n",
    "        'accuracy',\n",
    "        #\"precision\",    # The precision is intuitively the ability of the classifier not to label as positive a sample that is negative\n",
    "        #\"recall\",       # The recall is intuitively the ability of the classifier to find all the positive samples.\n",
    "        ]\n",
    "    for score in scores:\n",
    "        log_hyperparameter_search(\"\\t--- [%s] Running Parameter-Tests [LINEAR-PCA-SVC] ---\" % datetime.now())\n",
    "        log_hyperparameter_search(\"\\tTuning parameters for criteria [%s]\" % score)\n",
    "        # FIXME: Doesn't take accuracy as score for some reason. Refer to line below for accuracy score\n",
    "        #grid = GridSearchCV(estimator=svm, param_grid=parameters, scoring=\"%s_macro\" % score, verbose=3)\n",
    "        grid = GridSearchCV(estimator=svm, param_grid=parameters, scoring='accuracy', verbose=3, n_jobs=-1)\n",
    "        grid.fit(pca_train_data, train_label)\n",
    "\n",
    "        log_hyperparameter_search(\"\\tBest parameters set found on following development set:\")\n",
    "        log_hyperparameter_search(\"\\t\\tSupport Vector: %s\" % grid.best_estimator_)\n",
    "        log_hyperparameter_search(\"\\t\\tSupport Vector Parametrization: %s\" % grid.best_params_)\n",
    "        log_hyperparameter_search(\"\\t\\tAsserted Score: %s\" % grid.best_score_)\n",
    "        log_hyperparameter_search(\"Total Score \\t\\t Configurations\")\n",
    "\n",
    "        means = grid.cv_results_[\"mean_test_score\"]\n",
    "        stds = grid.cv_results_[\"std_test_score\"]\n",
    "        params = grid.cv_results_[\"params\"]\n",
    "        for mean, std, params in zip(means, stds, params):\n",
    "            log_hyperparameter_search(\"%0.3f (+/-%0.03f)\\t%r\" % (mean, std, params))\n",
    "        print(\"Wrote classifier comparisons to file \", hyperparameter_search_log)\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\")\n",
    "    \n",
    "        y_true, y_pred = test_label, grid.predict(pca_test_data)\n",
    "        log_hyperparameter_search(classification_report(y_true, y_pred))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poly SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained new model: {'Kernel':'poly'} in 38.11026358604431 seconds\n",
      "\t[poly]: mean accuracy on train-data: 0.9965331022068138; execution time: 33.05199384689331s\n",
      "\t[poly]: mean accuracy on test-data: 0.9555822328931572; execution time: 6.724902629852295s\n"
     ]
    }
   ],
   "source": [
    "# Evalute SVM.SVC with parameters on data below\n",
    "svm = SVC(kernel='poly')\n",
    "start_time = time.time()\n",
    "svm.fit(pca_train_data, train_label)\n",
    "end_time = time.time() - start_time\n",
    "log_training_results(\"Trained new model: {'Kernel':'%s'} in %s seconds\" % (svm.get_params()[\"kernel\"], end_time))\n",
    "\n",
    "start_time = time.time()\n",
    "score = svm.score(pca_train_data, train_label)\n",
    "end_time = time.time() - start_time\n",
    "log_training_results(\"\\t[%s]: mean accuracy on train-data: %s; execution time: %ss\" % (svm.get_params()[\"kernel\"], score, end_time))  \n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "score = svm.score(pca_test_data, test_label)\n",
    "end_time = time.time() - start_time\n",
    "log_training_results(\"\\t[%s]: mean accuracy on test-data: %s; execution time: %ss\" % (svm.get_params()[\"kernel\"], score, end_time))  \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter search -- Takes up a long time.\n",
    "if config.hyper_parameter_search:\n",
    "    svm = SVC()\n",
    "    parameters = {\n",
    "            \"kernel\":[\"poly\"], \n",
    "            \"C\":[1,10,50,100],            \n",
    "            \"gamma\":[0.01,0.005,0.001,0.0005,0.0001],        \n",
    "            #\"coef0\":[0.0, 0.5],\n",
    "            #\"degree\":[3,5,10],                \n",
    "            #\"shrinking\":[True,False],      \n",
    "            #\"probability\":[True,False], \n",
    "            #\"tol\":[0.01,0.001,0.0001],\n",
    "    }\n",
    "    scores = [\n",
    "        \"accuracy\",\n",
    "        #\"precision\",    # The precision is intuitively the ability of the classifier not to label as positive a sample that is negative\n",
    "        #\"recall\",       # The recall is intuitively the ability of the classifier to find all the positive samples.\n",
    "        ]\n",
    "    for score in scores:\n",
    "        log_hyperparameter_search(\"--- [%s] Running Parameter-Tests [POLY-PCA-SVC] ---\" % datetime.now())\n",
    "        log_hyperparameter_search(\"\\tTuning parameters for criteria [%s]\" % score)\n",
    "        # FIXME: Doesn't take accuracy as score for some reason. Refer to line below for accuracy score\n",
    "        #grid = GridSearchCV(estimator=svm, param_grid=parameters, scoring=\"%s_macro\" % score, verbose=3)\n",
    "        grid = GridSearchCV(estimator=svm, param_grid=parameters, scoring='accuracy', verbose=3, n_jobs=-1)\n",
    "        grid.fit(pca_train_data, train_label)\n",
    "\n",
    "        log_hyperparameter_search(\"\\tBest parameters set found on following development set:\")\n",
    "        log_hyperparameter_search(\"\\t\\tSupport Vector: %s\" % grid.best_estimator_)\n",
    "        log_hyperparameter_search(\"\\t\\tSupport Vector Parametrization: %s\" % grid.best_params_)\n",
    "        log_hyperparameter_search(\"\\t\\tAsserted Score: %s\" % grid.best_score_)\n",
    "        log_hyperparameter_search(\"Total Score \\t\\t Configurations\")\n",
    "\n",
    "        means = grid.cv_results_[\"mean_test_score\"]\n",
    "        stds = grid.cv_results_[\"std_test_score\"]\n",
    "        params = grid.cv_results_[\"params\"]\n",
    "        for mean, std, params in zip(means, stds, params):\n",
    "            log_hyperparameter_search(\"%0.3f (+/-%0.03f)\\t%r\" % (mean, std, params))\n",
    "        print(\"Wrote classifier comparisons to file \", hyperparameter_search_log)\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\")\n",
    "    \n",
    "        y_true, y_pred = test_label, grid.predict(pca_test_data)\n",
    "        log_hyperparameter_search(classification_report(y_true, y_pred))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBF SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained new model: {'Kernel':'rbf'} in 21.55874800682068 seconds\n",
      "\t[rbf]: mean accuracy on train-data: 0.9928661910794053; execution time: 63.37735438346863s\n",
      "\t[rbf]: mean accuracy on test-data: 0.9551820728291317; execution time: 10.86228084564209s\n"
     ]
    }
   ],
   "source": [
    "# Evalute SVM.SVC with parameters on data below\n",
    "svm = SVC(kernel='rbf')\n",
    "start_time = time.time()\n",
    "svm.fit(pca_train_data, train_label)\n",
    "end_time = time.time() - start_time\n",
    "log_training_results(\"Trained new model: {'Kernel':'%s'} in %s seconds\" % (svm.get_params()[\"kernel\"], end_time))\n",
    "\n",
    "start_time = time.time()\n",
    "score = svm.score(pca_train_data, train_label)\n",
    "end_time = time.time() - start_time\n",
    "log_training_results(\"\\t[%s]: mean accuracy on train-data: %s; execution time: %ss\" % (svm.get_params()[\"kernel\"], score, end_time))  \n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "score = svm.score(pca_test_data, test_label)\n",
    "end_time = time.time() - start_time\n",
    "log_training_results(\"\\t[%s]: mean accuracy on test-data: %s; execution time: %ss\" % (svm.get_params()[\"kernel\"], score, end_time))  \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter search -- Takes up a long time.\n",
    "if config.hyper_parameter_search:\n",
    "    svm = SVC()\n",
    "    parameters = {\n",
    "            \"kernel\":[\"rbf\"], \n",
    "            \"C\":[1,10,50,100],            \n",
    "            \"gamma\":[0.01,0.005,0.001,0.0005,0.0001],        \n",
    "            #\"shrinking\":[True,False],      \n",
    "            #\"probability\":[True,False], \n",
    "            #\"tol\":[0.01,0.001,0.0001],\n",
    "    }\n",
    "    scores = [\n",
    "        \"accuracy\",\n",
    "        #\"precision\",    # The precision is intuitively the ability of the classifier not to label as positive a sample that is negative\n",
    "        #\"recall\",       # The recall is intuitively the ability of the classifier to find all the positive samples.\n",
    "        ]\n",
    "    for score in scores:\n",
    "        log_hyperparameter_search(\"--- [%s] Running Parameter-Tests [RBF-PCA-SVC] ---\" % datetime.now())\n",
    "        log_hyperparameter_search(\"\\tTuning parameters for criteria [%s]\" % score)\n",
    "        # FIXME: Doesn't take accuracy as score for some reason. Refer to line below for accuracy score\n",
    "        #grid = GridSearchCV(estimator=svm, param_grid=parameters, scoring=\"%s_macro\" % score, verbose=3)\n",
    "        grid = GridSearchCV(estimator=svm, param_grid=parameters, scoring='accuracy', verbose=3, n_jobs=-1)\n",
    "        grid.fit(pca_train_data, train_label)\n",
    "\n",
    "        log_hyperparameter_search(\"\\tBest parameters set found on following development set:\")\n",
    "        log_hyperparameter_search(\"\\t\\tSupport Vector: %s\" % grid.best_estimator_)\n",
    "        log_hyperparameter_search(\"\\t\\tSupport Vector Parametrization: %s\" % grid.best_params_)\n",
    "        log_hyperparameter_search(\"\\t\\tAsserted Score: %s\" % grid.best_score_)\n",
    "        log_hyperparameter_search(\"Total Score \\t\\t Configurations\")\n",
    "\n",
    "        means = grid.cv_results_[\"mean_test_score\"]\n",
    "        stds = grid.cv_results_[\"std_test_score\"]\n",
    "        params = grid.cv_results_[\"params\"]\n",
    "        for mean, std, params in zip(means, stds, params):\n",
    "            log_hyperparameter_search(\"%0.3f (+/-%0.03f)\\t%r\" % (mean, std, params))\n",
    "        print(\"Wrote classifier comparisons to file \", hyperparameter_search_log)\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\")\n",
    "    \n",
    "        y_true, y_pred = test_label, grid.predict(pca_test_data)\n",
    "        log_hyperparameter_search(classification_report(y_true, y_pred))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained new model: {'Kernel':'sigmoid'} in 14.930679321289062 seconds\n",
      "\t[sigmoid]: mean accuracy on train-data: 0.8842589505967065; execution time: 25.45977258682251s\n",
      "\t[sigmoid]: mean accuracy on test-data: 0.8563425370148059; execution time: 4.271034240722656s\n"
     ]
    }
   ],
   "source": [
    "# Evalute SVM.SVC with parameters on data below\n",
    "svm = SVC(kernel='sigmoid')\n",
    "start_time = time.time()\n",
    "svm.fit(pca_train_data, train_label)\n",
    "end_time = time.time() - start_time\n",
    "log_training_results(\"Trained new model: {'Kernel':'%s'} in %s seconds\" % (svm.get_params()[\"kernel\"], end_time))\n",
    "\n",
    "start_time = time.time()\n",
    "score = svm.score(pca_train_data, train_label)\n",
    "end_time = time.time() - start_time\n",
    "log_training_results(\"\\t[%s]: mean accuracy on train-data: %s; execution time: %ss\" % (svm.get_params()[\"kernel\"], score, end_time))  \n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "score = svm.score(pca_test_data, test_label)\n",
    "end_time = time.time() - start_time\n",
    "log_training_results(\"\\t[%s]: mean accuracy on test-data: %s; execution time: %ss\" % (svm.get_params()[\"kernel\"], score, end_time))  \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter search -- Takes up a long time.\n",
    "if config.hyper_parameter_search:\n",
    "    svm = SVC()\n",
    "    parameters = {\n",
    "            \"kernel\":[\"sigmoid\"], \n",
    "            \"C\":[1,10,50,100],            \n",
    "            \"gamma\":[0.01,0.005,0.001,0.0005,0.0001],        \n",
    "            #\"shrinking\":[True,False],      \n",
    "            #\"probability\":[True,False], \n",
    "            #\"tol\":[0.01,0.001,0.0001],\n",
    "    }\n",
    "    scores = [\n",
    "        \"accuracy\",\n",
    "        #\"precision\",    # The precision is intuitively the ability of the classifier not to label as positive a sample that is negative\n",
    "        #\"recall\",       # The recall is intuitively the ability of the classifier to find all the positive samples.\n",
    "        ]\n",
    "    for score in scores:\n",
    "        log_hyperparameter_search(\"--- [%s] Running Parameter-Tests [SIGMOID-PCA-SVC] ---\" % datetime.now())\n",
    "        log_hyperparameter_search(\"\\tTuning parameters for criteria [%s]\" % score)\n",
    "        # FIXME: Doesn't take accuracy as score for some reason. Refer to line below for accuracy score\n",
    "        #grid = GridSearchCV(estimator=svm, param_grid=parameters, scoring=\"%s_macro\" % score, verbose=3)\n",
    "        grid = GridSearchCV(estimator=svm, param_grid=parameters, scoring='accuracy', verbose=3, n_jobs=-1)\n",
    "        grid.fit(pca_train_data, train_label)\n",
    "\n",
    "        log_hyperparameter_search(\"\\tBest parameters set found on following development set:\")\n",
    "        log_hyperparameter_search(\"\\t\\tSupport Vector: %s\" % grid.best_estimator_)\n",
    "        log_hyperparameter_search(\"\\t\\tSupport Vector Parametrization: %s\" % grid.best_params_)\n",
    "        log_hyperparameter_search(\"\\t\\tAsserted Score: %s\" % grid.best_score_)\n",
    "        log_hyperparameter_search(\"Total Score \\t\\t Configurations\")\n",
    "\n",
    "        means = grid.cv_results_[\"mean_test_score\"]\n",
    "        stds = grid.cv_results_[\"std_test_score\"]\n",
    "        params = grid.cv_results_[\"params\"]\n",
    "        for mean, std, params in zip(means, stds, params):\n",
    "            log_hyperparameter_search(\"%0.3f (+/-%0.03f)\\t%r\" % (mean, std, params))\n",
    "        print(\"Wrote classifier comparisons to file \", hyperparameter_search_log)\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\")\n",
    "    \n",
    "        y_true, y_pred = test_label, grid.predict(pca_test_data)\n",
    "        log_hyperparameter_search(classification_report(y_true, y_pred))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e2b2785e650337f79381cd4c5df08c4d5dc4623a6a0d2da7e01465b331d0fcc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
