[2022-09-12 19:55:12.927919] on (Windows-10-10.0.19044-SP0, Intel64 Family 6 Model 140 Stepping 1, GenuineIntel) using (Train: 15000, Test: 2500)
--- [2022-09-12 19:55:24.113296] Running Parameter-Tests [SKLEARN-NN] ---
	Best parameters set found on following development set:
		Support Vector: MLPClassifier(alpha=0.05, hidden_layer_sizes=(784,))
		Support Vector Parametrization: {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'constant', 'solver': 'adam'}
		Asserted Score: 0.965997532510837
Total Score 		 Configurations
0.929 (+/-0.011)	{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'constant', 'solver': 'sgd'}
0.938 (+/-0.008)	{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'constant', 'solver': 'adam'}
0.928 (+/-0.013)	{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'adaptive', 'solver': 'sgd'}
0.935 (+/-0.006)	{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'adaptive', 'solver': 'adam'}
0.915 (+/-0.013)	{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (784,), 'learning_rate': 'constant', 'solver': 'sgd'}
0.953 (+/-0.005)	{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (784,), 'learning_rate': 'constant', 'solver': 'adam'}
0.915 (+/-0.014)	{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (784,), 'learning_rate': 'adaptive', 'solver': 'sgd'}
0.952 (+/-0.005)	{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (784,), 'learning_rate': 'adaptive', 'solver': 'adam'}
0.929 (+/-0.011)	{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'constant', 'solver': 'sgd'}
0.945 (+/-0.008)	{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'constant', 'solver': 'adam'}
0.928 (+/-0.013)	{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'adaptive', 'solver': 'sgd'}
0.943 (+/-0.004)	{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'adaptive', 'solver': 'adam'}
0.916 (+/-0.014)	{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'constant', 'solver': 'sgd'}
0.957 (+/-0.004)	{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'constant', 'solver': 'adam'}
0.915 (+/-0.014)	{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'adaptive', 'solver': 'sgd'}
0.957 (+/-0.003)	{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'adaptive', 'solver': 'adam'}
0.930 (+/-0.013)	{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'constant', 'solver': 'sgd'}
0.938 (+/-0.006)	{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'constant', 'solver': 'adam'}
0.930 (+/-0.012)	{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'adaptive', 'solver': 'sgd'}
0.937 (+/-0.006)	{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'adaptive', 'solver': 'adam'}
0.937 (+/-0.011)	{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (784,), 'learning_rate': 'constant', 'solver': 'sgd'}
0.963 (+/-0.003)	{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (784,), 'learning_rate': 'constant', 'solver': 'adam'}
0.938 (+/-0.010)	{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (784,), 'learning_rate': 'adaptive', 'solver': 'sgd'}
0.964 (+/-0.003)	{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (784,), 'learning_rate': 'adaptive', 'solver': 'adam'}
0.929 (+/-0.012)	{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'constant', 'solver': 'sgd'}
0.946 (+/-0.006)	{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'constant', 'solver': 'adam'}
0.931 (+/-0.012)	{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'adaptive', 'solver': 'sgd'}
0.941 (+/-0.007)	{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'adaptive', 'solver': 'adam'}
0.938 (+/-0.010)	{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'constant', 'solver': 'sgd'}
0.966 (+/-0.004)	{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'constant', 'solver': 'adam'}
0.937 (+/-0.010)	{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'adaptive', 'solver': 'sgd'}
0.964 (+/-0.007)	{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'adaptive', 'solver': 'adam'}
              precision    recall  f1-score   support

         0.0       0.96      0.99      0.97       219
         1.0       0.98      0.98      0.98       287
         2.0       0.97      0.95      0.96       276
         3.0       0.94      0.98      0.96       254
         4.0       0.97      0.96      0.96       275
         5.0       0.97      0.97      0.97       221
         6.0       0.95      0.95      0.95       225
         7.0       0.94      0.95      0.94       256
         8.0       0.95      0.95      0.95       242
         9.0       0.95      0.93      0.94       244

    accuracy                           0.96      2499
   macro avg       0.96      0.96      0.96      2499
weighted avg       0.96      0.96      0.96      2499

--- [2022-09-12 20:59:07.136552] Running Parameter-Tests [SKLEARN-NN-PCA] ---
	Best parameters set found on following development set:
		Support Vector: MLPClassifier(alpha=0.05, hidden_layer_sizes=(784,), max_iter=100)
		Support Vector Parametrization: {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'constant', 'solver': 'adam'}
		Asserted Score: 0.9667308436145381
Total Score 		 Configurations
0.913 (+/-0.011)	{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'constant', 'solver': 'sgd'}
0.913 (+/-0.008)	{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'constant', 'solver': 'adam'}
0.914 (+/-0.011)	{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'adaptive', 'solver': 'sgd'}
0.913 (+/-0.010)	{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'adaptive', 'solver': 'adam'}
0.906 (+/-0.016)	{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (784,), 'learning_rate': 'constant', 'solver': 'sgd'}
0.904 (+/-0.011)	{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (784,), 'learning_rate': 'constant', 'solver': 'adam'}
0.906 (+/-0.015)	{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (784,), 'learning_rate': 'adaptive', 'solver': 'sgd'}
0.904 (+/-0.012)	{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (784,), 'learning_rate': 'adaptive', 'solver': 'adam'}
0.911 (+/-0.012)	{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'constant', 'solver': 'sgd'}
0.931 (+/-0.007)	{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'constant', 'solver': 'adam'}
0.912 (+/-0.012)	{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'adaptive', 'solver': 'sgd'}
0.930 (+/-0.007)	{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'adaptive', 'solver': 'adam'}
0.907 (+/-0.015)	{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'constant', 'solver': 'sgd'}
0.952 (+/-0.005)	{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'constant', 'solver': 'adam'}
0.907 (+/-0.014)	{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'adaptive', 'solver': 'sgd'}
0.954 (+/-0.006)	{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'adaptive', 'solver': 'adam'}
0.925 (+/-0.012)	{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'constant', 'solver': 'sgd'}
0.924 (+/-0.010)	{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'constant', 'solver': 'adam'}
0.925 (+/-0.012)	{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'adaptive', 'solver': 'sgd'}
0.923 (+/-0.010)	{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'adaptive', 'solver': 'adam'}
0.931 (+/-0.011)	{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (784,), 'learning_rate': 'constant', 'solver': 'sgd'}
0.948 (+/-0.007)	{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (784,), 'learning_rate': 'constant', 'solver': 'adam'}
0.931 (+/-0.011)	{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (784,), 'learning_rate': 'adaptive', 'solver': 'sgd'}
0.949 (+/-0.007)	{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (784,), 'learning_rate': 'adaptive', 'solver': 'adam'}
0.926 (+/-0.013)	{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'constant', 'solver': 'sgd'}
0.940 (+/-0.004)	{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'constant', 'solver': 'adam'}
0.927 (+/-0.011)	{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'adaptive', 'solver': 'sgd'}
0.937 (+/-0.007)	{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'adaptive', 'solver': 'adam'}
0.931 (+/-0.012)	{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'constant', 'solver': 'sgd'}
0.967 (+/-0.004)	{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'constant', 'solver': 'adam'}
0.931 (+/-0.011)	{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'adaptive', 'solver': 'sgd'}
0.966 (+/-0.004)	{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'adaptive', 'solver': 'adam'}
              precision    recall  f1-score   support

         0.0       0.95      0.99      0.97       219
         1.0       0.98      0.98      0.98       287
         2.0       0.96      0.95      0.95       276
         3.0       0.96      0.98      0.97       254
         4.0       0.97      0.96      0.96       275
         5.0       0.99      0.94      0.96       221
         6.0       0.96      0.95      0.96       225
         7.0       0.94      0.93      0.94       256
         8.0       0.95      0.96      0.95       242
         9.0       0.94      0.95      0.95       244

    accuracy                           0.96      2499
   macro avg       0.96      0.96      0.96      2499
weighted avg       0.96      0.96      0.96      2499

[2022-09-13 01:12:13.210585] on (Windows-10-10.0.19044-SP0, Intel64 Family 6 Model 140 Stepping 1, GenuineIntel) using (Train: 15000, Test: 2500)
--- [2022-09-13 01:12:24.296055] Running Parameter-Tests [SKLEARN-NN] ---
	Best parameters set found on following development set:
		Support Vector: MLPClassifier(alpha=0.05, hidden_layer_sizes=(784,))
		Support Vector Parametrization: {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'constant', 'solver': 'adam'}
		Asserted Score: 0.9678643770145605
Total Score 		 Configurations
0.929 (+/-0.011)	{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'constant', 'solver': 'sgd'}
0.936 (+/-0.007)	{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'constant', 'solver': 'adam'}
0.928 (+/-0.009)	{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'adaptive', 'solver': 'sgd'}
0.938 (+/-0.007)	{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'adaptive', 'solver': 'adam'}
0.915 (+/-0.013)	{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (784,), 'learning_rate': 'constant', 'solver': 'sgd'}
0.953 (+/-0.004)	{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (784,), 'learning_rate': 'constant', 'solver': 'adam'}
0.916 (+/-0.013)	{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (784,), 'learning_rate': 'adaptive', 'solver': 'sgd'}
0.952 (+/-0.004)	{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (784,), 'learning_rate': 'adaptive', 'solver': 'adam'}
0.930 (+/-0.011)	{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'constant', 'solver': 'sgd'}
0.945 (+/-0.003)	{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'constant', 'solver': 'adam'}
0.929 (+/-0.010)	{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'adaptive', 'solver': 'sgd'}
0.944 (+/-0.006)	{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'adaptive', 'solver': 'adam'}
0.914 (+/-0.012)	{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'constant', 'solver': 'sgd'}
0.958 (+/-0.007)	{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'constant', 'solver': 'adam'}
0.915 (+/-0.013)	{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'adaptive', 'solver': 'sgd'}
0.957 (+/-0.005)	{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'adaptive', 'solver': 'adam'}
0.928 (+/-0.013)	{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'constant', 'solver': 'sgd'}
0.938 (+/-0.005)	{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'constant', 'solver': 'adam'}
0.931 (+/-0.012)	{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'adaptive', 'solver': 'sgd'}
0.939 (+/-0.008)	{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'adaptive', 'solver': 'adam'}
0.937 (+/-0.011)	{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (784,), 'learning_rate': 'constant', 'solver': 'sgd'}
0.963 (+/-0.004)	{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (784,), 'learning_rate': 'constant', 'solver': 'adam'}
0.938 (+/-0.012)	{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (784,), 'learning_rate': 'adaptive', 'solver': 'sgd'}
0.962 (+/-0.004)	{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (784,), 'learning_rate': 'adaptive', 'solver': 'adam'}
0.930 (+/-0.011)	{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'constant', 'solver': 'sgd'}
0.938 (+/-0.009)	{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'constant', 'solver': 'adam'}
0.930 (+/-0.013)	{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'adaptive', 'solver': 'sgd'}
0.941 (+/-0.008)	{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'adaptive', 'solver': 'adam'}
0.935 (+/-0.009)	{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'constant', 'solver': 'sgd'}
0.968 (+/-0.002)	{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'constant', 'solver': 'adam'}
0.938 (+/-0.012)	{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'adaptive', 'solver': 'sgd'}
0.964 (+/-0.005)	{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'adaptive', 'solver': 'adam'}
              precision    recall  f1-score   support

         0.0       0.94      0.99      0.96       219
         1.0       0.98      0.98      0.98       287
         2.0       0.97      0.95      0.96       276
         3.0       0.95      0.98      0.97       254
         4.0       0.96      0.96      0.96       275
         5.0       0.99      0.93      0.96       221
         6.0       0.97      0.94      0.95       225
         7.0       0.96      0.93      0.94       256
         8.0       0.94      0.96      0.95       242
         9.0       0.93      0.95      0.94       244

    accuracy                           0.96      2499
   macro avg       0.96      0.96      0.96      2499
weighted avg       0.96      0.96      0.96      2499

--- [2022-09-13 02:16:13.743436] Running Parameter-Tests [SKLEARN-NN-PCA] ---
	Best parameters set found on following development set:
		Support Vector: MLPClassifier(alpha=0.05, hidden_layer_sizes=(784,), learning_rate='adaptive',
              max_iter=100)
		Support Vector Parametrization: {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'adaptive', 'solver': 'adam'}
		Asserted Score: 0.9664641769478715
Total Score 		 Configurations
0.912 (+/-0.016)	{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'constant', 'solver': 'sgd'}
0.914 (+/-0.012)	{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'constant', 'solver': 'adam'}
0.912 (+/-0.013)	{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'adaptive', 'solver': 'sgd'}
0.916 (+/-0.010)	{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'adaptive', 'solver': 'adam'}
0.907 (+/-0.013)	{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (784,), 'learning_rate': 'constant', 'solver': 'sgd'}
0.906 (+/-0.012)	{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (784,), 'learning_rate': 'constant', 'solver': 'adam'}
0.908 (+/-0.014)	{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (784,), 'learning_rate': 'adaptive', 'solver': 'sgd'}
0.905 (+/-0.012)	{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (784,), 'learning_rate': 'adaptive', 'solver': 'adam'}
0.913 (+/-0.012)	{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'constant', 'solver': 'sgd'}
0.932 (+/-0.009)	{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'constant', 'solver': 'adam'}
0.913 (+/-0.012)	{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'adaptive', 'solver': 'sgd'}
0.931 (+/-0.007)	{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'adaptive', 'solver': 'adam'}
0.907 (+/-0.015)	{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'constant', 'solver': 'sgd'}
0.954 (+/-0.005)	{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'constant', 'solver': 'adam'}
0.906 (+/-0.015)	{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'adaptive', 'solver': 'sgd'}
0.955 (+/-0.003)	{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'adaptive', 'solver': 'adam'}
0.925 (+/-0.010)	{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'constant', 'solver': 'sgd'}
0.922 (+/-0.009)	{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'constant', 'solver': 'adam'}
0.922 (+/-0.012)	{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'adaptive', 'solver': 'sgd'}
0.924 (+/-0.008)	{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'adaptive', 'solver': 'adam'}
0.931 (+/-0.011)	{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (784,), 'learning_rate': 'constant', 'solver': 'sgd'}
0.949 (+/-0.007)	{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (784,), 'learning_rate': 'constant', 'solver': 'adam'}
0.930 (+/-0.011)	{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (784,), 'learning_rate': 'adaptive', 'solver': 'sgd'}
0.949 (+/-0.007)	{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (784,), 'learning_rate': 'adaptive', 'solver': 'adam'}
0.924 (+/-0.011)	{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'constant', 'solver': 'sgd'}
0.940 (+/-0.006)	{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'constant', 'solver': 'adam'}
0.921 (+/-0.010)	{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'adaptive', 'solver': 'sgd'}
0.940 (+/-0.007)	{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'adaptive', 'solver': 'adam'}
0.930 (+/-0.010)	{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'constant', 'solver': 'sgd'}
0.966 (+/-0.004)	{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'constant', 'solver': 'adam'}
0.932 (+/-0.012)	{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'adaptive', 'solver': 'sgd'}
0.966 (+/-0.004)	{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'adaptive', 'solver': 'adam'}
              precision    recall  f1-score   support

         0.0       0.96      0.98      0.97       219
         1.0       0.98      0.98      0.98       287
         2.0       0.95      0.96      0.96       276
         3.0       0.96      0.97      0.96       254
         4.0       0.96      0.97      0.97       275
         5.0       0.99      0.94      0.96       221
         6.0       0.96      0.95      0.95       225
         7.0       0.95      0.94      0.94       256
         8.0       0.93      0.95      0.94       242
         9.0       0.95      0.95      0.95       244

    accuracy                           0.96      2499
   macro avg       0.96      0.96      0.96      2499
weighted avg       0.96      0.96      0.96      2499

[2022-09-13 06:27:55.066690] on (Windows-10-10.0.19044-SP0, Intel64 Family 6 Model 140 Stepping 1, GenuineIntel) using (Train: 15000, Test: 2500)
--- [2022-09-13 06:28:05.635430] Running Parameter-Tests [SKLEARN-NN] ---
	Best parameters set found on following development set:
		Support Vector: MLPClassifier(alpha=0.05, hidden_layer_sizes=(784,), learning_rate='adaptive')
		Support Vector Parametrization: {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'adaptive', 'solver': 'adam'}
		Asserted Score: 0.9655973324441481
Total Score 		 Configurations
0.929 (+/-0.011)	{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'constant', 'solver': 'sgd'}
0.937 (+/-0.010)	{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'constant', 'solver': 'adam'}
0.929 (+/-0.011)	{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'adaptive', 'solver': 'sgd'}
0.937 (+/-0.008)	{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'adaptive', 'solver': 'adam'}
0.916 (+/-0.014)	{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (784,), 'learning_rate': 'constant', 'solver': 'sgd'}
0.952 (+/-0.004)	{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (784,), 'learning_rate': 'constant', 'solver': 'adam'}
0.915 (+/-0.013)	{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (784,), 'learning_rate': 'adaptive', 'solver': 'sgd'}
0.953 (+/-0.005)	{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (784,), 'learning_rate': 'adaptive', 'solver': 'adam'}
0.928 (+/-0.013)	{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'constant', 'solver': 'sgd'}
0.944 (+/-0.006)	{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'constant', 'solver': 'adam'}
0.930 (+/-0.011)	{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'adaptive', 'solver': 'sgd'}
0.944 (+/-0.009)	{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'adaptive', 'solver': 'adam'}
0.915 (+/-0.014)	{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'constant', 'solver': 'sgd'}
0.960 (+/-0.004)	{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'constant', 'solver': 'adam'}
0.915 (+/-0.013)	{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'adaptive', 'solver': 'sgd'}
0.957 (+/-0.005)	{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'adaptive', 'solver': 'adam'}
0.931 (+/-0.011)	{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'constant', 'solver': 'sgd'}
0.938 (+/-0.006)	{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'constant', 'solver': 'adam'}
0.930 (+/-0.013)	{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'adaptive', 'solver': 'sgd'}
0.937 (+/-0.008)	{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'adaptive', 'solver': 'adam'}
0.938 (+/-0.010)	{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (784,), 'learning_rate': 'constant', 'solver': 'sgd'}
0.963 (+/-0.005)	{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (784,), 'learning_rate': 'constant', 'solver': 'adam'}
0.936 (+/-0.011)	{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (784,), 'learning_rate': 'adaptive', 'solver': 'sgd'}
0.962 (+/-0.005)	{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (784,), 'learning_rate': 'adaptive', 'solver': 'adam'}
0.931 (+/-0.011)	{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'constant', 'solver': 'sgd'}
0.943 (+/-0.007)	{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'constant', 'solver': 'adam'}
0.934 (+/-0.009)	{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'adaptive', 'solver': 'sgd'}
0.942 (+/-0.006)	{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'adaptive', 'solver': 'adam'}
0.937 (+/-0.011)	{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'constant', 'solver': 'sgd'}
0.965 (+/-0.003)	{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'constant', 'solver': 'adam'}
0.937 (+/-0.010)	{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'adaptive', 'solver': 'sgd'}
0.966 (+/-0.004)	{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'adaptive', 'solver': 'adam'}
              precision    recall  f1-score   support

         0.0       0.96      0.98      0.97       219
         1.0       0.98      0.98      0.98       287
         2.0       0.96      0.96      0.96       276
         3.0       0.96      0.97      0.97       254
         4.0       0.97      0.97      0.97       275
         5.0       0.98      0.96      0.97       221
         6.0       0.95      0.96      0.95       225
         7.0       0.94      0.95      0.95       256
         8.0       0.95      0.95      0.95       242
         9.0       0.96      0.95      0.96       244

    accuracy                           0.96      2499
   macro avg       0.96      0.96      0.96      2499
weighted avg       0.96      0.96      0.96      2499

--- [2022-09-13 07:31:28.416131] Running Parameter-Tests [SKLEARN-NN-PCA] ---
	Best parameters set found on following development set:
		Support Vector: MLPClassifier(alpha=0.05, hidden_layer_sizes=(784,), max_iter=100)
		Support Vector Parametrization: {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'constant', 'solver': 'adam'}
		Asserted Score: 0.9673976436589975
Total Score 		 Configurations
0.913 (+/-0.012)	{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'constant', 'solver': 'sgd'}
0.915 (+/-0.009)	{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'constant', 'solver': 'adam'}
0.913 (+/-0.014)	{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'adaptive', 'solver': 'sgd'}
0.914 (+/-0.009)	{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'adaptive', 'solver': 'adam'}
0.906 (+/-0.015)	{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (784,), 'learning_rate': 'constant', 'solver': 'sgd'}
0.904 (+/-0.011)	{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (784,), 'learning_rate': 'constant', 'solver': 'adam'}
0.906 (+/-0.015)	{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (784,), 'learning_rate': 'adaptive', 'solver': 'sgd'}
0.905 (+/-0.011)	{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (784,), 'learning_rate': 'adaptive', 'solver': 'adam'}
0.912 (+/-0.014)	{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'constant', 'solver': 'sgd'}
0.928 (+/-0.009)	{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'constant', 'solver': 'adam'}
0.914 (+/-0.013)	{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'adaptive', 'solver': 'sgd'}
0.931 (+/-0.007)	{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'adaptive', 'solver': 'adam'}
0.907 (+/-0.013)	{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'constant', 'solver': 'sgd'}
0.953 (+/-0.005)	{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'constant', 'solver': 'adam'}
0.906 (+/-0.014)	{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'adaptive', 'solver': 'sgd'}
0.951 (+/-0.005)	{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'adaptive', 'solver': 'adam'}
0.925 (+/-0.012)	{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'constant', 'solver': 'sgd'}
0.927 (+/-0.009)	{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'constant', 'solver': 'adam'}
0.924 (+/-0.009)	{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'adaptive', 'solver': 'sgd'}
0.926 (+/-0.007)	{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'adaptive', 'solver': 'adam'}
0.931 (+/-0.011)	{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (784,), 'learning_rate': 'constant', 'solver': 'sgd'}
0.948 (+/-0.007)	{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (784,), 'learning_rate': 'constant', 'solver': 'adam'}
0.931 (+/-0.012)	{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (784,), 'learning_rate': 'adaptive', 'solver': 'sgd'}
0.949 (+/-0.007)	{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (784,), 'learning_rate': 'adaptive', 'solver': 'adam'}
0.925 (+/-0.010)	{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'constant', 'solver': 'sgd'}
0.940 (+/-0.006)	{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'constant', 'solver': 'adam'}
0.926 (+/-0.009)	{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'adaptive', 'solver': 'sgd'}
0.938 (+/-0.009)	{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (28, 28), 'learning_rate': 'adaptive', 'solver': 'adam'}
0.931 (+/-0.010)	{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'constant', 'solver': 'sgd'}
0.967 (+/-0.003)	{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'constant', 'solver': 'adam'}
0.931 (+/-0.013)	{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'adaptive', 'solver': 'sgd'}
0.967 (+/-0.003)	{'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (784,), 'learning_rate': 'adaptive', 'solver': 'adam'}
              precision    recall  f1-score   support

         0.0       0.94      0.98      0.96       219
         1.0       0.97      0.98      0.98       287
         2.0       0.98      0.95      0.96       276
         3.0       0.95      0.98      0.96       254
         4.0       0.96      0.97      0.96       275
         5.0       0.97      0.95      0.96       221
         6.0       0.94      0.94      0.94       225
         7.0       0.96      0.92      0.94       256
         8.0       0.94      0.95      0.94       242
         9.0       0.95      0.95      0.95       244

    accuracy                           0.96      2499
   macro avg       0.96      0.96      0.96      2499
weighted avg       0.96      0.96      0.96      2499

